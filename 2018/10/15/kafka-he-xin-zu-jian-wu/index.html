<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Kafka-核心组件（五）, 编程 读书 生活">
    <meta name="description" content="
当捡起最后一片落叶，我就能看到整个春天。 ——秋水

5.2　日志管理器启动过程在对日志结构进行简要介绍之后，现在开始分析日志管理器的实现原理。首先分析日志管理器的启动过程。
当代理启动时首先实例化并启动一个日志管理器。实例化日志管理器时">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Kafka-核心组件（五） | Asxing-阿行</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <script src="/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Asxing-阿行" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Asxing-阿行</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Asxing-阿行</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/asxing" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/asxing" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/17.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        Kafka-核心组件（五）
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Kafka/">
                                <span class="chip bg-color">Kafka</span>
                            </a>
                        
                            <a href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">
                                <span class="chip bg-color">消息中间件</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Kafka/" class="post-category">
                                Kafka
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2018-10-15
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    21.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    77 分
                </div>
                
				
                
            </div>
            
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>当捡起最后一片落叶，我就能看到整个春天。 ——秋水</p>
</blockquote>
<h4 id="5-2-日志管理器启动过程"><a href="#5-2-日志管理器启动过程" class="headerlink" title="5.2　日志管理器启动过程"></a>5.2　日志管理器启动过程</h4><p>在对日志结构进行简要介绍之后，现在开始分析日志管理器的实现原理。首先分析日志管理器的启动过程。</p>
<p>当代理启动时首先实例化并启动一个日志管理器。实例化日志管理器时调用的构造方法如下：</p>
<pre><code>class LogManager(val logDirs: Array[File],  // 配置项log.dirs指定的消息存储目录
                 val topicConfigs: Map[String, LogConfig], // 主题级别的配置信息
                 val defaultConfig: LogConfig,  // 默认配置信息
                 val cleanerConfig: CleanerConfig, // 日志压缩相关的配置信息
                 ioThreads: Int,  // IO 线程数
                 val flushCheckMs: Long, // 日志刷写到磁盘的时间间隔
                 val flushCheckpointMs: Long, // 日志检查点写磁盘的时间间隔
                 val retentionCheckMs: Long,  // 日志清理的时间间隔
                 scheduler: Scheduler, // 后台定时任务组件
                 val brokerState: BrokerState, // Kafka 代理的状态
                 private val time: Time)</code></pre><p>从日志管理器的构造方法可以看到，日志管理器依赖于日志管理相关的配置及 Kafka 后台定时任务调度组件（KafkaScheduler）。</p>
<p>下面介绍一下日志管理器初始化过程。</p>
<p>首先，根据代理启动时加载的配置文件 server.properties 里配置项 log.dir 配置的分区文件存储路径（可以配置多个路径，多路径之间以逗号分隔）检查相应目录是否已存在，若不存在就创建相应的目录。并在每个根目录下创建一个用于对该目录操作控制的锁文件，文件名为 .lock，由于是以“.”开头的文件，因此这是一个隐藏文件，在 Linux 下需要通过 ll-a 或 ls-a 命令查看。同一时刻只能有一个日志管理器实例或线程来获取到该锁文件，该文件只有在日志管理器正常关闭，也就是 KafkaServer 正常关闭时才会被删除。通过该锁文件可以判断上次 KafkaServer 关闭是正常关闭还是异常关闭。同时创建或加载日志恢复检查点文件（recovery-point- offset-checkpoint），若该文件不存在，则创建一个新的检查点文件，该文件用来记录每个主题的每个分区下一次写入磁盘数据的偏移量，即小于该偏移量的数据已写入磁盘。例如，一个检查点文件如下：</p>
<pre><code>0
4
log-format 1 0
log-format 2 0
kafka-action 1 1
kafka-action 2 0</code></pre><p>该文件中第一行0表示版本号信息，当前版本的 Kafka 此值固定为0，第二行4表示有4条记录，由于每个分区对应一行记录，因此4也表示该目录下总共有4个分区目录。从第三行开始每个分区对应一行记录，每行记录的信息为主题名、分区编号、已写磁盘的数据偏移量。</p>
<p>接着，根据检查点文件加载和恢复日志文件，该过程是调用日志管理器的 loadLogs() 方法来实现。该方法遍历<code>${log.dir}</code>配置的路径，对每个路径进行以下处理。</p>
<p>（1）创建用于日志恢复的线程池。为每个路径创建一组固定大小为<code>${num.recovery.threads. per.data.dir }</code>的线程池，默认大小为1，并将线程池保存到 ArrayBuffer 集合中。</p>
<p>（2）检测<code>.kafka_cleanshutdown</code>文件。当代理上一次是正常关闭时，则在<code>${log.dir}</code>配置的每个路径创建下面会有一个 <code>.kafka_cleanshutdown</code> 文件。若该文件不存在，那么表示上一次代理是由于发生故障而关闭，当然也有可能是 KafkaServer 首次启动，因此在启动时会设置一个中间状态 RecoveringFromUncleanShutdown，Kafka 统一认为本次的启动都是从非正常关闭中恢复的。</p>
<p>（3）构建 Kafka 日志恢复工作集。根据 recovery-point-offset-checkpoint 文件记录信息，加载并恢复分配到当前代理的所有分区，每个分区对应一个 Log 对象，该对象封装了对 Kafka Log 的基本操作。将分区的 Log 信息缓存在 Pool[TopicAndPartition, Log] 对象中，Pool 是 Kafka 对 ConcurrentHashMap 集合进行的包装，其功能与 ConcurrentHashMap 类似，本书不做深入分析。</p>
<p>（4）将工作集提交到线程池执行。将执行结果保存到 Map 类型的 jobs 对象中。</p>
<p>通过以上4步操作之后，遍历 jobs 对象，等待线程执行完成，获取执行结果，然后删除<code>.kafka_cleanshutdown</code>文件，同时关闭用于恢复操作的线程池。至此，日志管理器完成了相关日志文件的恢复与加载。这里只是简要地梳理了日志恢复与加载的流程，在3.5.3节将更详细地介绍。</p>
<p>然后，若开启了日志定时清理功能，则实例化一个 LogCleaner 对象。该功能默认是开启的，可以通过配置项 log.cleaner.enable 进行设置。LogCleaner 对象初始化时会创建<code>${log.cleaner.threads}</code>个清理线程，默认是创建一个清理线程。</p>
<p>最后，调用日志管理器的 startup() 方法启动日志管理器。在 startup() 方法中，若日志管理器初始时所依赖的后台定时任务调度组件不为空，则启动 3 个定时任务，分别为定期（log.retention. check.interval.ms）执行对过期日志的清理操作，定期（log.flush.scheduler.interval.ms）将日志刷到（flush）磁盘，定期（log.flush.offset.checkpoint.interval.ms）将分区已写磁盘的最大偏移量写入到检查点文件。同时，若开启了自动清理功能，则调用 LogCleaner 的 startup() 方法启动日志清理线程。</p>
<h4 id="5-3-日志加载及恢复"><a href="#5-3-日志加载及恢复" class="headerlink" title="5.3　日志加载及恢复"></a>5.3　日志加载及恢复</h4><p>在日志管理器初始化时，会调用 loadLogs() 方法加载和恢复 log.dir 配置项指定目录下的分区文件，为每个分区文件创建一个 Log 对象。该方法实现逻辑如下。</p>
<p>首先，定义一个 ArrayBuffer 类型的 threadPools 变量，用来保存线程池对象。再定义一个 Map 类型的 jobs 变量，用来记录实例化 Log 对象的线程执行结果。</p>
<p>接着，遍历 log.dir 指定的每个目录，对每个目录执行以下处理。</p>
<p>（1）创建一个大小为<code>${num.recovery.threads.per.data.dir}</code>的线程池，用来初始化和加载 Log 对象，日志文件的恢复是由 Log 对象来完成的。</p>
<p>（2）检查是否存在<code>.kafka_cleanshutdown</code>文件，该文件在代理正常关闭的情况下会被创建。若不存在该文件，则将代理的状态设置为 RecoveringFromUncleanShutdown，即表示代理启动过程有一个从上一次非正常关闭恢复数据的状态。</p>
<p>（3）将检查点文件解析成一个以 TopicAndParttion 对象为键、以偏移量作为值的 Map 集合（recoveryPoints）。</p>
<p>（4）为该目录下的每个分区目录（TopicName-PartitionId）创建一个初始化 Log 对象的任务，并将任务交由线程池处理。</p>
<p>（5）处理第4步任务执行结果，无异常时删除目录下面的<code>.kafka_cleanshutdown</code>文件。待所有任务处理完成后关闭线程池。</p>
<p>第4步中的每个任务的核心逻辑为：分别读取每个分区目录名，解析出分区对应的主题及分区编号，构造 TopicAndPartition 对象，从默认配置中提取该主题的配置信息，从检查点集合中取出该分区已写磁盘的最大偏移量，为每个分区目录实例化一个 Log 对象。Log 对象实例化依赖于 Kafka 后台调度定时任务组件 KafkaScheduler，Log 对象通过该定时任务异步将日志刷到磁盘。将实例化的 Log 对象与 TopicAndPartition 对应关系保存到日志管理器维护的一个 Pool[TopicAndPartition, Log] 集合中，由 Log 对象完成日志恢复操作。</p>
<p>Log 类在逻辑层面上可以理解为与分区对应，也就是说 Log 类封装了对一个分区的基本操作，从实现层面而言，也是对日志段（LogSegment）操作和管理的封装。在实例化 Log 对象时，Log 会完成该分区目录下所有日志段的恢复操作，并将日志段加载到 ConcurrentSkipListMap 类型的 segments 集合中。ConcurrentSkipListMap 具有跳跃表的功能，适用于高并发访问，多个线程可以安全地并发进行插入、删除、更新和访问操作，该集合的特性为通过偏移量快速查找日志提供了保证。</p>
<p>Log 恢复和加载日志段由 Log.loadSegments() 方法实现，具体逻辑如下。</p>
<p>（1）检查分区目录是否存在，若不存在则创建。</p>
<p>（2）遍历分区目录下的文件，根据文件后缀名分别进行不同的处理。若文件后缀为 .delete 或 .cleaned，则直接删除该文件。某个文件后缀名是 .delete 则表示该文件是需要被清除而还未执行删除操作，在删除一个日志段时首先会将该日志段对应的日志文件和两个索引文件的文件名后缀修改为 .delete，然后调用 LogSegment.delete() 方法删除该日志段对应的文件。文件名为 .cleaned 的文件表示是在日志清理操作第一阶段生成的临时文件。因此这两种类型的文件，在对日志段进行恢复操作时均应直接删除。若文件名后缀为 .swap，则先去掉 .swap 后缀，然后再判断文件是偏移量索引文件（.index）还是日志文件（.log）。若是偏移量索引文件则直接删除该文件，若是日志文件则删除该日志文件对应的索引文件，同时将该文件添加到<code>Set&lt;File&gt;</code>类型的 swapFiles 集合中。</p>
<p>（3）第二次遍历分区目录下的文件，依然根据文件后缀名分别进行处理。若是偏移量索引文件或时间戳索引文件（.timeindex），查找对应的日志文件是否则在，若日志文件不存在，则删除索引文件。若是日志文件，则创建一个 LogSegment 对象，如果该日志文件对应的偏移量索引文件存在，则检查两个索引文件是否有效，若索引文件无效则删除两个索引文件，同时调用 LogSegment.recover() 方法重新创建索引文件，若偏移量索引文件不存在则直接调用 LogSegment.recover() 方法创建索引文件。recover() 方法的核心思想就是读取日志文件，当累积字节数大于<code>${index.interval.bytes}</code>时插入一条索引记录，完成索引的重建。</p>
<p>（4）遍历 swapFiles 集合对 .swap 类型的文件进行处理。根据 .swap 文件名计算出基准偏移量，然后分别创建 LogSegment 对象并重建两个索引文件，查找以该 swap 段的基准偏移量开始与下一个日志段基准偏移量之间所有日志段文件，删除这些日志段对应的数据文件及其索引，然后去掉 .swap 后缀，并将该日志段加到 Log 对象的 segments 集合中。</p>
<p>（5）若 segments 为空，则说明通过以上几步恢复操作没有得到任何有效的日志段，为了保证该 Log 对象至少有一个活跃段，需要创建一个日志段，即创建活跃段的数据文件及该日志段对应的两个索引文件。若 segments 不为空，则调用 Log.recoverLog() 方法恢复日志段。该方法首先也是检测<code>.kafka_cleanshutdown</code>文件是否存在，若存在则无需进行数据恢复处理，只需更新检查点；否则获取所有未刷新的日志段，即检查点之后的所有日志段，通过日志段 LogSegment 的 recover() 方法重建两个索引文件，在遍历日志段的数据文件消息时会进行 CRC 验证，若验证失败则将该条消息之后的所有消息删除掉，即该日志段从校验失败的位置开始截取，取该条消息之前有效的数据，同时该日志段之后的所有日志段也被删除。最后将活跃段的两个索引文件大小设置为<code>${ segment.index.bytes }</code>。</p>
<p>至此，日志加载及恢复操作介绍完毕。通过以上分析可知，日志管理器对日志的加载和恢复是调用 Log 和 LogSegment 相应的方法来执行的。</p>
<h4 id="5-4-日志清理"><a href="#5-4-日志清理" class="headerlink" title="5.4　日志清理"></a>5.4　日志清理</h4><p>Kafka 将一个主题的每个分区副本分成多个日志段文件，这样通过定时日志清理操作，将旧的日志文件及时清理并释放出空间，以避免磁盘上的日志段文件过大而导致新的日志无法写入。同时分成多个日志段文件而不是一个文件也便于清理操作。正因为分成了多个日志段文件，所以我们可以通过日志段的更新时间或是日志段的大小控制进行日志清理。</p>
<p>Kafka 提供了日志删除（delete）和日志压缩（compact）两种清理日志的策略，通过参数 cleanup.policy 来指定日志清理的策略。日志清理粒度可以控制到主题级别，我们可以通过参数 cleanup.policy 为每个主题指定不同的清理策略。当然也可以在代理启动时通过配置项 log.cleanup.policy 指定日志清理策略，这样该代理上的所有分区日志清理默认使用该配置设置的策略，主题级别的策略设置会覆盖代理级别的配置。</p>
<h5 id="1．日志删除"><a href="#1．日志删除" class="headerlink" title="1．日志删除"></a>1．日志删除</h5><p>在日志管理器启动时会启动一个后台定时任务线程用于定时删除日志段文件。该删除线程每隔<code>${log.retention.check.interval.ms}</code>毫秒检查一次是否该进行日志删除，默认是每5分钟执行一次。</p>
<p>Kafka 提供了基于日志保留时长和日志段大小两种日志删除配置方式。基于日志保留时长的配置有 log.retention.hours、log.retention.minutes 和 log.retention.ms，这3种时间配置项的单位依次为时、分、毫秒，表示日志段保留时长，我们可以选择其中一个配置项来设置日志段文件的保留时长。默认是设置 log.retention.hours=168，即168小时，也就是说，日志段文件被保留7天之后会被清理。还有一种配置方式是通过配置项 log.retention.bytes 设置日志段大小。默认是不设置日志大小，即是以日志保留时长来进行日志删除操作，在实际业务中根据需要可以组合使用这两种配置方式。同样，若是主题级别的配置，则在相应的配置项前去掉“log.”前缀。</p>
<p>日志删除线程调用日志管理器的 cleanupLogs() 方法进行日志删除操作，该方法再调用 Log.deleteOldSegments() 方法查找并删除该待删除的日志段文件。该方法逻辑如代码清单 3-1所示。</p>
<p><strong>代码清单3-1　Log.deleteOldSegments() 方法的实现逻辑</strong></p>
<pre><code>def deleteOldSegments(): Int = {
    // 保证清理策略是 delete
    if (!config.delete) return 0
    // 查找基于保留时长及日志段大小的待删除的旧日志段文件
    deleteRetenionMsBreachedSegments() + deleteRetentionSizeBreachedSegments()
 }</code></pre><p>由代码清单3-1可知，删除时会通过 Log.deleteRetenionMsBreachedSegments() 方法查找保留时长超过预设值的待删除的日志段，以及通过 Log.deleteRetentionSizeBreachedSegments() 方法查找待删除的文件，以保证磁盘上的日志大小不超过<code>${ retention.bytes }</code>。若需要通过日志段大小来删除日志，需要保证<code>${retention.bytes}</code>的值大于0。</p>
<p>查找保留时长超时的日志段文件，并不是简单地依据日志段的最晚更新时间（lastModified）来计算，因为最晚更新时间并不能真实反映出该日志段在磁盘保留的时间，例如，在分区副本重分配时该日志段更新时间将会被修改。因此 Kafka 在计算日志段文件保留时长时会计算一个最长时间 largestTimestamp，以此时间与当前时间的差值作为是否删除该日志段的条件。最长时间的计算先是查询该日志段文件对应的时间戳索引文件，查找时间戳索引文件中最后一条时间记录，若最后一条时间记录值大于0，则最长时间取该时间索引值，否则取该日志段的最晚更新时间。之所以基于时间戳索引进行日志清除，是因为时间戳索引是严格依据时间递增，且与日志写入操作相对应的，日志段文件只要不是日志写入的修改并不会影响时间戳索引文件中记录的时间。</p>
<p>在计算出最长时间后，从最早日志段文件依次扫描直到第一个不满足超时条件的段文件结束，查找出所有待删除的日志段文件。若待删除的日志段总数等于该分区日志段总数，说明所有日志段的保留时间均已过期，但该分区下至少要有一个日志段用于接受消息的写入，因此这种情况下，需要切分成一个新的日志段，此时调用 Log.roll() 方法，创建一个新的日志段文件。然后迭代待删除的日志段文件，调用 Log.deleteSegment(segment: LogSegment) 方法执行删除操作。该方法首先会从 Log 维护的跳跃链表中移除待删除的日志段，以保证没有线程对该日志段文件进行读操作，然后异步调用 Log.asyncDeleteSegment() 方法进行物理删除。在 Log.asyncDeleteSegment() 方法中其实是新启动了一个名为“delete-file”的定时任务线程进行删除。在删除开始时首先将日志段文件及其两个索引文件重命名为以“.deleted”为后缀的文件，然后调用 FileMessageSet.delete() 方法最终将日志段文件及其索引文件删除。</p>
<p>基于日志段大小的删除与基于日志保留时长的删除类似，首先计算日志段总大小（size）与<code>${retention.bytes}</code>之间的差值（diff），即需要删除的日志总大小，然后从第一个日志段开始查找，若 diff 与该日志段字节之差不小于0，则将该日志段加入到待删除集合中，以此类推，直到 diff 与查找的日志段大小之差小于0，查找结束。查找出待删除的日志段集合后，迭代待删除的日志段文件，物理删除处理逻辑与基于日志保留时间的删除方式相同，不再阐述。</p>
<h5 id="2．日志压缩"><a href="#2．日志压缩" class="headerlink" title="2．日志压缩"></a>2．日志压缩</h5><p>另外一种日志清理的策略为日志压缩。这种策略是一种更细粒度的清理策略，它基于消息的 Key，通过压缩每个 Key 对应的消息只保留最后一个版本的数据，该 Key 对应的其他版本在压缩时会被清除，类似数据库的更新操作。压缩策略将 Key 对应的值为空的消息，认为是直接删除该条消息。为了不影响日志追加操作，日志压缩并不会对活跃段进行操作。同时，对除活跃段之外日志段压缩也不是一次性执行，而是分批进行。若某个主题要开启日志压缩的策略，首先需要保证 log.cleaner.enable=true，默认是开启。然后设置主题级别的日志清理策略配置项为“compact”。</p>
<p>日志管理器启动时会实例化一个 LogCleaner 对象，在该对象实例化时会创建一个 LogCleanerManager 对象，该对象负责日志压缩状态的管理，清理检查点文件（cleaner-offset-checkpoint）的更新及查找需要压缩的日志文件。</p>
<p>Kafka 的日志压缩状态有3种，当 Log 开始进行压缩时压缩状态为 LogCleaningInProgress，当压缩任务为暂停时就会进入 LogCleaningPaused，当压缩被终止时就会转换为 LogCleaningAborted 状态。暂停和终止状态时不会进行日志压缩，需要等其他线程将其恢复为压缩状态，这几种压缩状态我们不展开分析。清理检查点文件与日志恢复检查点文件功能类似，记录每个主题的每个分区 TopicAndPartition 清理的偏移量。通过该文件，可以将数据文件分成两部分，一部分是已经过压缩操作的 clean 段，另一部分是未经过压缩操作的 dirty 段。其中经过压缩的 clean 段中的偏移量不是连续递增的，而 dirty 段的偏移量则是连续递增的。根据清理检查点将日志文件切分为 clean 和 dirty 两部分示意图如图3-23所示。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/Log 由检查点切分为 clean 与 dirty 两部分.png)</p>
<p>图3-23　Log 由检查点切分为 clean 与 dirty 两部分</p>
<p>同时 LogCleaner 对象实例化时还创建了<code>${log.cleaner.threads}</code>个用于日志清理的线程 CleanerThread，默认创建一个线程，CleanerThread 是日志压缩的操作线程，该线程继承 ShutdownableThread，实现了 ShutdownableThread 提供的抽象方法 doWork() 方法，doWork() 方法是线程 run() 方法的真正执行体，是日志压缩操作的入口。在该方法中调用的是 CleanerThread. cleanOrSleep() 方法。下面详细分析 cleanOrSleep() 方法的执行逻辑。</p>
<p>（1）通过 CleanerManager.grabFilthiestCompactedLog() 方法查找满足压缩条件的 Log，即可清理比例大于预设阈值并且 Log 没有处于 LogCleaningInProgress 状态。Kafka 将该满足压缩条件的日志定义为 LogToClean 对象，该对象维护了每个 Log 的 clean 段字节数、第一个可清理的 dirty 段位置、第一个不可清理的消息位置以及可清理比例（cleanableRatio），还提供了清理比例比较的 compare() 方法。其中可清理比例是指 dirty 段的字节总数与日志段总字节数之比，只有当 Log 可清理比例不小于<code>${ min.cleanable.dirty.ratio}</code>时，即代理级别的配置 log.cleaner.min.cleanable.ratio 默认为 0.5，才有可能成为被压缩的对象。</p>
<p>（2）通过 Cleaner 对象的 clean() 方法执行真正的压缩逻辑。Cleaner 对象是一个对日志执行真正压缩操作逻辑的封装类。clean() 方法从本次需要清理的日志起始位置与最大结束位置开始遍历，将每个消息的 Key 及该 Key 对应消息的偏移量保存到一个固定容量的 SkimpyOffsetMap 中，由于是 Map，因此当 Key 相同时后面的值会覆盖先前的值，这样就保证了相同 Key 的消息只保留最晚的值。需要说明的是，这里的 Key 并不是消息实际的 Key，而是 Key 进行 MD5 操作后的 Hash 值。最大结束位置显然是活跃段的起始位置，因为活跃段不参与日志压缩，而本次压缩操作真实的结束位置（endOffset）是取 SkimpyOffsetMap 的最大容量与最大结束位置两者中的小者。</p>
<p>（3）根据日志的最晚更新时间与<code>${delete.retention.ms}</code>计算需要删除的日志时间戳，记为 deleteHorizonMs，日志段的最晚时间与该时间戳比较作为日志段是否保留的判断条件之一。</p>
<p>（4）将 Log 从 0 到 endOffset 的消息以 LogSegment 为单位进行分组，每组 LogSegment 字节大小不超过 log.config.segmentSize，每组索引大小不能超过 log.config.maxIndexSize。分组之后通过 Cleaner.cleanSegments() 方法进行压缩。该方法首先创建一个以“.cleaned”为后缀的数据文件及两个以“.cleaned”为后缀的索引文件。然后对组内的每个 LogSegment 调用 Cleaner.cleanInto() 方法执行真正的压缩。压缩操作的实质是将满足保留条件的消息复制到以“.cleaned”为后缀的数据文件中。消息是否可保留需要满足以下条件。</p>
<ul>
<li>消息的 Key 不为空，因为为空即表示该 Key 对应的消息将被删除。</li>
<li>消息在 SkimpyOffsetMap 中存在，且偏移量更大。</li>
<li>日志段的最晚时间大于 deleteHorizonMs。</li>
</ul>
<p>（5）对两个索引文件进行处理，去掉多余的索引项，同时将压缩后的日志段数据刷到磁盘。</p>
<p>（6）更新压缩后的日志段的最后修改时间，然后调用 Log.replaceSegments() 方法进行处理，将文件后缀由“.cleaned”修改为“.swap”，并将压缩后的日志段加入到 segments 集合中，然后将分组中的所有 LogSegment 从 Log 的 segments 集合中删除，并执行对这些日志段的删除操作。最后将“.swap”后缀去掉。</p>
<p>至此，日志压缩的整个过程介绍完毕。需要注意将日志清理与日志删除区分开，日志删除是删除整个日志段，而日志清理是将相同 key 的日志进行合并，只保留该 key 最后一个值，将合并后的数据构成新的日志段，同时删除原来的日志段。日志压缩过程示意图如图3-24所示。</p>
<p><img src="../../../../../../../../../../../../images/2018/10/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9%E8%BF%87%E7%A8%8B.png" alt="enter image description here"></p>
<p>图3-24　日志压缩过程</p>
<h3 id="6-副本管理器"><a href="#6-副本管理器" class="headerlink" title="6　副本管理器"></a>6　副本管理器</h3><p>在 Kafka 0.8 版本中引入了副本机制，引入副本机制使得 Kafka 能够在整个集群中只要保证至少有一个代理存活就不会影响整个集群的工作，从而大大提高了 Kafka 集群的可靠性和稳定性。这里提到代理存活的概念，同其他分布式系统一样，Kafka 对代理是否存活（alive）也有明确的定义，Kafka 存活要满足两个条件。</p>
<p>（1）一个存活的节点必须与 ZooKeeper 保持连接，维护与 ZooKeeper 的 Session（这是通过 ZooKeeper 的心跳机制来实现的）。</p>
<p>（2）如果一个节点作为 Follower 副本，该节点必须能及时与分区的 Leader 副本保持消息同步，不能落后太久。</p>
<p>准确来讲，满足以上两个条件的节点应该是同步中的（in sync）节点，Leader 副本会追踪所有同步中的节点，一旦一个节点宕机、卡住或是延迟太久，Leader 就会将该节点从同步副本（in sync replicas）集合列表中移除。至于代理何时被认为是已卡住或者数据同步落后 Leader 太久是由配置项<code>${replica.lag.time.max.ms}</code>决定的，默认情况下该配置项设置为10秒。在 Kafka 0.9 之前的版本，还通过配置项<code>${replica.lag.max.messages}</code>配置 Follower 落后 Leader 的消息条数来定义某个代理是否已落后太多，然而在 0.9 之后的版本中已移除该配置项，因为该配置项并不能真实反映出一个代理是否已落后太多，例如，当某一时刻生产者发送来的消息数大于<code>${replica.lag.max.messages}</code>时，在这一时刻所有的副本均视为落后太多，会被 Leader 从同步列表中移除，显然不合理。</p>
<p>我们可以在代理启动时加载的配置文件 server.properties 中通过配置项 default.replication.factor=n 来配置副本数量（这里 n 为副本数），默认情况下，Kafka 的副本数为 1，该配置项配置了主题默认所拥有的副本数，如我们通过生产者向一个不存在的主题发送消息，当配置项 auto.create. topics.enable=true 时，Kafka 会自动创建生产者指定的主题，该主题拥有<code>${default.replication.factor}</code>个副本。我们也可以在创建主题时通过设置–replication-factor n 为每个主题分别指定副本数，创建主题时指定的副本数会覆盖 default.replication.factor 配置的值。这样一个副本为 n 的集群就允许 n−1 个节点失败而不会影响整个集群的工作。</p>
<p>在所有的副本节点中，有一个节点作为 Leader 负责接收客户端的读写操作，其他副本节点作为 Follower 从 Leader 节点复制数据进行数据同步。这里的复制机制既不是同步复制，也不是单纯的异步复制。因为同步复制要求“活着的” Follower 都从 Leader 复制完消息，这条消息才被认为是已提交（commit）。对生产者而言，生产者可以通过 offsets.commit.required.acks 参数来设置选择等待消息被提交的方式，而只有被提交的消息才能被消费者消费。同步方式极大地影响了吞吐率。而异步复制方式下，Follower 异步地从 Leader 复制数据，消息只要被 Leader 写入数据文件中就被认为已经提交，这种情况下如果 Follower 都落后于 Leader，而 Leader 突然宕机，则会丢失数据。Kafka 采用维护一种同步列表的方式很好地均衡了确保数据不丢失以及吞吐率的问题。</p>
<p>副本管理器（ReplicaManager）负责对副本管理，主要包括对控制器发送的 LeaderAndIsrRequest 指令、StopReplicaRequest 指令以及UpdateMetadataRequest 指令进行处理，维护副本 ISR 变化，以及 Follower 与 Leader 数据同步的管理。</p>
<p>在介绍副本管理器基本功能之前，首先简要介绍分区和副本的相关知识。因为从底层实现来看，副本管理器对副本的管理体现在对分区的管理，副本管理器提供了创建或获取分区相关方法，如 getOrCreatePartition() 方法，而分区又封装了对副本的管理，因为副本是相对分区而言的，即副本是特定分区的副本，副本管理器对副本的管理调用也是分区操作副本的方法，如获取分区副本的 getReplica()、获取或创建副本的 getOrCreateReplica() 等。</p>
<h4 id="6-1-分区"><a href="#6-1-分区" class="headerlink" title="6.1　分区"></a>6.1　分区</h4><p>Kafka 将一个主题在逻辑上分成一个或多个分区，每个分区在物理存储上对应一个目录，目录名为<code>${topicName}-${partitionId}</code>，其中<code>${topicName}</code>是主题的名字，<code>${partitionId}</code>是分区编号，每个主题的分区都有唯一编号，分区编号从0依次递增。分区目录下存储的是该分区的日志段，包括日志数据文件和两个索引文件。每个分区又对应一个或多个副本。需要注意的是，分区数可以大于节点数，但副本数不能大于节点数，因为副本需要分布在不同的节点上，这样才能达到备份的目的。</p>
<p>在创建主题时，若是以 Kafka 命令行创建主题，通过–partitons 参数指定分区数，也可以在代理启动时所加载的 server.properties 配置文件中通过配置参数 num.partitions 来指定默认分区数。假设我们在一个有3个节点的 Kafka 集群上创建一个 kafka-action 的主题，该主题有3个分区，每个分区只有一个副本，则会在<code>${log.dir}</code>目录下创建一个分区目录，分区在集群代理分布结构示意图如图3-25所示。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/kafka-action 主题3个分区在代理上的分布情况.png)</p>
<p>图3-25　kafka-action 主题3个分区在代理上的分布情况</p>
<p>由图3-25可知，当集群有3个节点时，3个分区均匀地分布在3个节点上。通常为了保证主题的分区均匀分布到集群中，建议在创建主题时指定分区数为代理节点数的整数倍。当生产者向主题发送消息时会根据分区分配策略将消息分发到该主题相应的分区，Kafka 保证同一个分区的数据是有序的，因此我们可以认为每个分区就是一个有序的消息队列。当生产者向一个主题写数据时，我们以 kafka-action 主题为例，该主题各分区存储数据逻辑结构示意图如图3-26所示。</p>
<p>对于图3-26所示的每个分区，在存储结构上有 LEO 和 HW 两个重要的概念。</p>
<p>LEO 是 Log End Offset 的缩写，表示每个分区最后一条消息的位置，分区的每个副本都有自己的 LEO。</p>
<p>HW 是 HighWatermark 的缩写，将一个分区对应的 ISR 中最小的 LEO 作为 HW，HW 之前的消息表示已提交的消息，对消费者是可见的，消费者最多只能消费到 HW 所在的位置。HW 之后的消息表示还没有被 Follower 副本同步完成。每个副本都有自己的 HighWatermark。副本 Leader 和 Follower 各自负责更新自己的 HighWatermark 状态，<code>Follower.HW &lt;= leader.LEO</code>。</p>
<p><img src="../../../../../../../../images/2018/10/%E5%88%86%E5%8C%BA%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E7%9A%84%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84.png" alt="enter image description here"></p>
<p>图3-26　分区存储数据的逻辑结构</p>
<p>LEO 和 HW 其实是 LogOffsetMetadata 对象的 messageOffset。Kafka 将日志的每个偏移量对应的位置封装成一个 LogOffsetMetadata 对象，该对象包括记录消息偏移量的 messageOffset 字段以及该偏移量对应的日志在日志段中的相对位置（relativePositionInSegment）字段，以及日志段的基准偏移量（segmentBaseOffset）。因此我们说的 LEO 和 HW 其实均指 LogOffsetMetadata 对象的 messageOffset 字段，只不过二者对应在日志中的位置不同而已。LEO 是日志文件中最后一条消息的位置，HW 是表示 ISR 列表中各副本 LEO 最小值。</p>
<p>对于分区的 Leader 副本，LEO 与 HW 的存储逻辑示意图如图3-27所示。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/LEO 与 HW 的逻辑结构.png)</p>
<p>图3-27　LEO 与 HW 的逻辑结构</p>
<p>每个主题的某一个分区只能被同一个消费组下的其中一个消费者消费，因此我们说分区是消费并行度的基本单位。同时，对于上层应用而言分区也是最小的存储单元，尽管每个分区是由一系列有序的顺序段组成的。从消费者角度来讲，我们订阅消费一个主题，也就是订阅了该主题的所有分区，当然也可以订阅主题的某个分区。从生产者角度来讲，我们可以通过指定消息的 Key 及分区分配策略将消息发送到主题相应的分区当中。</p>
<p>Kafka 将分区抽象为一个 Partition 对象，Partition 定义了一个 assignedReplicaMap 引用用于保存该分区所有副本，assignedReplicaMap 是一个 Pool 类型对象，并维护了该分区同步的副本集合 inSyncReplicas，同时 Patition 对象定义了分区对副本操作的方法，包括创建副本、副本角色切换、ISR 列表维护以及调用日志管理器（LogManager）追加消息等。分区对副本操作的方法由副本管理器在对副本管理时调用。对于这些方法的实现细节我们不展开介绍，在副本管理器对副本管理操作逻辑中会适当进行讲解。</p>
<h4 id="6-2-副本"><a href="#6-2-副本" class="headerlink" title="6.2　副本"></a>6.2　副本</h4><p>一个分区可以有一个或多个副本，副本根据是否接受读写请求，又分为 Leader 副本和 Follower 副本，一个分区有1个 Leader 副本，有0个或多个 Follower 副本。Leader 副本处理分区的所有读写请求并维护自身及 Follower 副本的状态信息，如 LEO、HW 等，Follower 副本作为消费者从 Leader 副本拉取消息进行同步。当 Leader 失效时，通过分区 Leader 选举器从副本列表中选出一个副本作为新的 Leader。</p>
<p>Kafka 将副本抽象为一个 Replica 对象，由于副本是属于某个主题的某个分区，分布在特定代理之上，因此 Replica 对象的基本属性包括主题（topic）、分区编号（partitionId）和代理编号（brokerId）。当副本的 brokerId 与当前代理的 brokerId 相同时，我们将该副本称为当前代理的本地副本，否则称为远程副本。</p>
<p>同时，副本还有 LEO、HW、副本追加数据的 Log 以及上次与 Leader 同步的时间，因此还有 logEndOffsetMetadata、highWatermarkMetadata、Log 和 lastCaughtUpTimeMsUnderlying 属性字段。对于远程副本而言，Log 字段对应的值为 null，因为远程副本的 Log 并不在当前代理上。logEndOffsetMetadata 表示已追加到 Log 的最新消息对应的偏移量，不过本地副本和远程副本获取此字段值的方式不同，本地副本可以通过 log.get.logEndOffsetMetadata 来获取副本的 LEO，远程副本由于 Log 属性为空，因此并不能直接从本地获取，而该字段的值是由远程副本对应的代理发送请求进行更新。对于 Follower 副本 highWatermarkMetadata 的值是从 Leader 副本获取更新。</p>
<p>对于一个有多副本的分区，如修改 kafka-action 主题的副本数为2，则该主题各分区副本在 Kafka 集群分布上的示意图如图3-28所示。当然，若分区只有一个副本时则该副本即为 Leader 副本。</p>
<p><img src="../../../../../../../../images/2018/10/%E5%88%86%E5%8C%BA%E5%A4%9A%E5%89%AF%E6%9C%AC%E5%88%86%E5%B8%83.png" alt="enter image description here"></p>
<p>图3-28　分区多副本分布</p>
<h4 id="6-3-副本管理器启动过程"><a href="#6-3-副本管理器启动过程" class="headerlink" title="6.3　副本管理器启动过程"></a>6.3　副本管理器启动过程</h4><p>每个代理启动时，都会启动一个副本管理器，副本管理器的实例化依赖于任务调度器实例、日记管理器实例以及用于副本同步限流控制的限流器（ReplicationQuotaManager）实例。实例化过程具体逻辑如下。</p>
<p>（1）创建一个用于记录控制器发生变化次数的 controllerEpoch 字段，初始值为0。同时创建一个 Pool[(String, Int), Partition] 对象用于保存该代理节点上的所有分区，该 Pool 保存了分配到该节点的每个主题的每个分区编号与分区的映射关系，将 Pool 对象记为 allPartitions。</p>
<p>（2）创建一个用于副本数据同步的线程管理组件 ReplicaFetcherManager，该组件创建依赖 ReplicationQuotaManager 对象，而实质是创建一个用于处理副本抓取请求的线程 ReplicaFetcherThread。</p>
<p>（3）加载或创建<code>${log.dri}</code>配置的所有存储路径下的 HW 检查点文件，文件名为 replication- offset-checkpoint，因此在每个代理启动时我们都会在<code>${log.dir}</code>目录下看到一个 replication- offset-checkpoint 文件，该文件记录每个分区已被提交（committed）的最大偏移量。</p>
<p>（4）创建一个用于保存分区 ISR 变化的 Set 类型的 isrChangeSet 集合对象，并创建一个 AtomicLong 类型的 lastIsrChangeMs 和 lastIsrPropagationMs 对象，分别用于记录新的 ISR 信息成功写入 ZooKeeper 的<code>/brokers/topics/${topicName}/partitions/${partitionId}/state</code>节点的时间，以及 ISR 变化信息写入 ZooKeeper 的<code>/isr_change_notification/isr_change_</code>节点的时间，以触发 IsrChangeNotificationListener 监听器通知代理更新缓存的 ISR 信息，这些字段在 ISR 发生变化时会被更新。</p>
<p>（5）为当前的代理创建 DelayedProduce 和 DelayedFetch 两个基于条件触发的延迟操作，这两个延迟操作交由 DelayedOperationPurgatory 监视，DelayedOperationPurgatory 是延迟操作的辅助类，以泛型的方式接收需要该辅助类监视的具体延迟对象。之所以在副本管理器启动时需要创建 DelayedProduce，是由于在生产者发送消息时，若设置了 acks 为−1，则需要等待 ISR 中的所有副本都从 Leader 同步完数据或在等待时间超时后再向生产者返回信息，也就是说不能立即向生产者做出响应，这就要发挥 DelayedProduce 的功能，每次 Follower 向 Leader 发送 FetchRequest 请求时，DelayedOperationPurgatory 会检测是否满足所监视的 DelayedProduce 执行条件，若满足了 DelayedProduce 执行条件，则在其 onComplete() 方法中回调向生产者返回写操作结果的方法。同理，在 Follower 副本向 Leader 副本发送 FetchRequest 请求时也可能不能立即得到返回响应，如 Leader 正在处理消息写入，这样为了让 Follower 拉取到更多的消息，即对 LEO 进行后移处理，此时就会延迟提取（Fetch）操作。</p>
<p>当实例化完成后调用 startup() 方法启动 ReplicaManager 时，在该方法中会启动两个后台定时任务。</p>
<p>（1）第一个定时任务“isr-expiration”用于定期检查过期的副本，将过期副本从 ISR 列表剔除，收缩 ISR。若有与 Leader 副本数据不同步的副本则从原 ISR 中剔除不同步的副本节点，构造新的 ISR 集合，并在 ZooKeeper 的<code>/brokers/topics/${topicName}/partitions/${partitionId}/state</code>路径下更新最新的ISR信息。</p>
<p>（2）第二个定时任务“isr-change-propagation”用于定时将 ISR 发生变化的分区编号信息写到 ZooKeeper 的<code>/isr_change_notification/isr_change_</code>节点中。</p>
<h4 id="6-4-副本过期检查"><a href="#6-4-副本过期检查" class="headerlink" title="6.4　副本过期检查"></a>6.4　副本过期检查</h4><p>副本管理器启动时启动了一个对副本过期检查的定时任务，该定时任务调用副本管理器的 maybeShrinkIsr() 方法定期进行副本过期检查。从这个函数的名字可以看出，其功能就是检查分区 ISR 是否需要进行收缩，即从 ISR 剔除与 Leader 数据不同步的副本。</p>
<p>在 ReplicaManager.maybeShrinkIsr() 方法中将轮询当前代理的所有分区 allPartitions，调用分区的 maybeShrinkIsr() 方法执行过期副本的检查。分区的 maybeShrinkIsr() 方法具体实现逻辑如代码清单3-2所示（去掉了非核心逻辑）。</p>
<p><strong>代码清单3-2　分区收缩ISR列表的Partition.maybeShrinkIsr()方法的具体逻辑</strong></p>
<pre><code>def maybeShrinkIsr(replicaMaxLagTimeMs: Long) {
    val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {
      leaderReplicaIfLocal() match {
        // 查找是否有过期副本
        case Some(leaderReplica) =&gt;
        val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs) 
        // 存在过期副本
        if(outOfSyncReplicas.nonEmpty) { 
           // 从该分区当前同步的 ISR 集合中移除过期的副本作为新的ISR集合
           val newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas 
           // 由于 ISR 发送了变化，因此请求更新该分区在ZooKeeper中记录的ISR信息
           updateIsr(newInSyncReplicas) 
           // 用于 metrics 信息收集
           replicaManager.isrShrinkRate.mark()
           // 由于 ISR 发生了变化，所以检查 Leader 的 HW 是否需要更新，
           // 以保证 Leader 的 HW 为 ISR 发生变化后各副本偏移量最小值
           maybeIncrementLeaderHW(leaderReplica) 
         } else {
           false
         }

        case None =&gt; false 
      }
    }

    // 如果更新了分区 Leader 的 HW，尝试运行当前分区被延迟执行的操作
    if (leaderHWIncremented)
      tryCompleteDelayedRequests()
  }</code></pre><p>当 Follower 副本已将 Leader 副本 LEO 之前的日志全部同步时，则该 Follower 已追赶上 Leader，此时会以当前时间更新该副本的 lastCaughtUpTimeMs 字段。从代码清单3-2可知，副本过期检查任务的第一步就是查找该分区的过期副本。通过调用分区的 getOutOfSyncReplicas() 方法，该方法主要逻辑如代码清单3-3所示。</p>
<p><strong>代码清单3-3　Partition.getOutOfSyncReplicas()方法的核心逻辑</strong></p>
<pre><code>val leaderLogEndOffset = leaderReplica.logEndOffset // Leader副本的LEO
val candidateReplicas = inSyncReplicas – leaderReplica // Follower 副本
val laggingReplicas = candidateReplicas.filter(r =&gt; (time.milliseconds - r.lastCaughtUpTimeMs) &gt; maxLagMs) // 查找 Follower 副本上次追上 Leader 的 LEO 的时间与当前时间
                                 // 之差大于 Follower 副本落后 Leader 副本最大时间的阈值的副本
if(laggingReplicas.nonEmpty)
  debug(&quot;Lagging replicas for partition %s are %s&quot;.format(TopicAndPartition(topic, partitionId), laggingReplicas.map(_.brokerId).mkString(&quot;,&quot;)))
laggingReplicas // 返回查找的落后 Leader 的 Follower 副本</code></pre><p>获取不同步 Follower 副本的主要逻辑就是检查当前 ISR 列表中 Follower 副本的 lastCaughtUpTimeMs 与当前时间之差是否超过<code>${replica.lag.time.max.ms}</code>值，若超过了该值，则分区 Leader 认为该 Follower 副本与其不同步，应该从 ISR 中移除。在找出需要移除的副本之后，重新构造 ISR 集合，并请求将最新的 ISR 信息写入 ZooKeeper 的<code>/brokers/topics/${topicName}/ partitions/${partitionId}/state</code>节点中，该节点信息的变化会触发相关监听器通知代理更新缓存中的 ISR 信息。 在将新 ISR 列表信息成功写入 ZooKeeper 后，更新副本管理器缓存的 isrChangeSet 和 lastIsrChangeMs 字段的值，并更新分区维护的同步副本集合 inSyncReplicas 信息及 zkVersion 信息。最后调用 Partition.maybeIncrementLeaderHW() 检查是否需要更新 Leader 的 HW，若更新过分区 Leader 的 ISR 信息，则尝试运行当前分区被延迟执行的操作，即 DelayedProduce 和 DelayedFetch 操作。</p>
<p>下面介绍更新 Leader 副本 HW 的 maybeIncrementLeaderHW() 方法的主要逻辑。</p>
<p>首先将该分区的所有副本 LEO 进行排序，取各副本 LEO 最小值作为 Leader 副本新的 HW，记为 newHighWatermark。newHighWatermark 是一个 LogOffsetMetadata 对象，这里说的 LEO 及 HW 均指 LogOffsetMetadata 对象的 messageOffset 属性值，取当前 Leader 副本的 HW 记为 oldHighWatermark。</p>
<p>然后判断是否满足更新 Leader 副本 HW 的条件，更新条件如下。</p>
<ul>
<li>比较<code>oldHighWatermark.messageOffset&lt;newHighWatermark.messageOffset</code>是否成立，也就是比较两者的 HW 值。</li>
<li>比较<code>oldHighWatermark.segmentBaseOffset&lt;newHighWatermark.segmentBaseOffset</code>是否成立，也就是判断是否已有新的日志段生成。</li>
</ul>
<p>满足以上两个条件之一，就需要更新 Leader 副本的 HW，即将 newHighWatermark 赋值给 Leader 副本的 highWatermarkMetadata。</p>
<p>副本过期检查逻辑较简单，对于每个分区的过期副本检查的基本流程如图3-29所示。</p>
<p><img src="../../../../../../../../images/2018/10/%E8%BF%87%E6%9C%9F%E5%89%AF%E6%9C%AC%E6%A3%80%E6%9F%A5%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B.png" alt="enter image description here"></p>
<p>图3-29　过期副本检查基本流程</p>
<h4 id="6-5-追加消息"><a href="#6-5-追加消息" class="headerlink" title="6.5　追加消息"></a>6.5　追加消息</h4><p>当生产者发送消息（ProduceRequest）或是消费者提交偏移量到内部主题时，由副本管理器的 appendMessages() 将消息追加到相应分区的 Leader 副本中。该方法定义如下：</p>
<pre><code>appendMessages(timeout: Long,          ⇽--- DelayedProduce延迟时长
               requiredAcks: Short,        ⇽--- acks 方式
               internalTopicsAllowed: Boolean,        ⇽---是否允许写入内部主题标识
               messagesPerPartition: Map[TopicPartition, MessageSet],      ⇽---待写入的消息与分区映射关系
               responseCallback: Map[TopicPartition, PartitionResponse] =&gt; Unit)      ⇽---写操作结果响应回调函数</code></pre><p>该方法第四个参数是一个 Map 对象，保存了本次写操作消息所对应的主题和分区，生产者可以订阅多个主题，在一次发送时会将多个主题发送到同一个分区的消息一起发送到分区的 Leader 副本，最后一个入参是一个回调函数 responseCallback，用于根据 acks 值，当消息成功写入或者处理时间超时后向客户端做出响应。副本管理器调用 appendMessages() 方法将消息写入 Leader 副本的处理逻辑如下。</p>
<p>首先，检查 acks 值是否合法。当前版本的 Kafka 支持的 acks 值为0、−1、1，若调用 appendMessages() 方法入参 acks 不为这3个值中之一时，则表示 acks 不合法，会直接回调 responseCallback，返回<code>Errors.INVALID_REQUIRED_ACKS</code>应答码。若 acks 合法，则会调用 ReplicaManager.appendToLocalLog() 方法将消息写入 Leader 副本，并得到各 TopicPartition 对应的消息追加操作状态。由于只有 Leader 副本才能处理客户端的读写请求，因此副本管理器也即为 Leader 副本对应的代理所启动的 ReplicaManager，所以写入 Leader 副本也就是由副本管理器将消息写入本地副本。需要注意的是，Leader 副本和本地副本没有直接联系，两者定义出发点不同。</p>
<p>然后，检查是否满足需要延迟生产操作（DelayedProduce）。若同时满足以下3个条件，则需要创建 DelayedProduce 延迟操作。</p>
<p>（1）acks==−1，即 ISR 列表中的所有 Follower 副本要从 Leader 副本将消息同步到本地。</p>
<p>（2）messagesPerPartition 集合不为空，即消息与主题和分区映射关系不能为空，客户端本次请求需要有数据写入。</p>
<p>（3）至少要对一个分区的消息追加操作成功。</p>
<p>若满足创建延迟操作的条件，则创建一个 DelayedProduce 对象并交由 delayedProducePurgatory 管理，由 DelayedProduce 在 onComplete() 方法中回调 responseCallback，向客户端返回追加操作结果状态。否则直接回调 responseCallback 将 appendToLocalLog() 方法对各 TopicPartition 消息追加操作的状态返回给客户端。</p>
<p>下面详细讲解副本管理器的 appendToLocalLog() 方法是如何将消息写入本地副本的。</p>
<p>ReplicaManager.appendToLocalLog() 方法迭代 messagesPerPartition 集合中的每个元素，检查消息写入主题是否是 Kafka 的内部主题，若是内部主题同时要判断是否允许对内部主题（<code>“__consumer_ offsets”</code>）的追加，当前版本的 Kafka 只允许组协调器将相应的元信息信息以及消费者消费偏移量追加到内部主题。如果消息写入的主题为 Kafka 内部主题，同时该消息又不允许被写入内部主题，此时对此消息的追加操作就要记为失败，即构造一个 LogAppendResult 对象，该对象有两个属性，消息追加的结果 LogAppendInfo 类型的 info 字段，以及一个标识消息追加异常的 Throwable 类型的 error 字段。当消息追加成功构造 LogAppendResult 时，此 error 为 Errors.NONE。当向 Kafka 内部主题追加消息而又不被允许时，LogAppendInfo 对象的 info为UnknownLogAppendInfo，error 为 InvalidTopicException。如果消息待追加的主题不为 Kafka 内部主题或者虽然是内部主题但该消息被允许追加，调用该消息对应分区的 appendMessagesToLeader() 方法将消息写入 Leader 副本。</p>
<p>Partition.appendMessagesToLeader() 方法首先获取该分区的 Leader 副本，然后检测 ISR 列表中副本数 inSyncSize 是否大于配置的最小同步副本数 minIsr，minIsr 取值为<code>${ min.insync.replicas }</code>，默认值为1。若<code>inSyncSize&lt;minIsr</code>，同时 acks 又为−1，则抛出 NotEnoughReplicasException 异常，否则调用 Log.append() 方法将消息追加到日志文件中。由于在日志追加时会更新 LEO，为了让一次拉取操作尽可能返回更多的消息，可能触发了 DelayedFetch 延迟操作，因此这里需要调用 ReplicaManager. tryCompleteDelayedFetch() 方法尝试将延迟拉取操作执行完成。同样由于消息的追加，应该调用分区的 maybeIncrementLeaderHW() 对 HW 检测并进行相应的处理。如果 HW 进行了更新操作，这里需要解锁延迟操作，即检测尝试让 DelayedProduce 和 DelayedFetch 执行完成。最后将追加结果返回给外部调用者即 ReplicaManager.appendToLocalLog()，在该方法中会对 Partition.appendMessagesToLeader() 方法处理过程中抛出的异常进行处理封装为相应的 LogAppendResult 对象。</p>
<p>至此，副本管理器对消息的追加操作讲解完毕。图3-30以时序图形式展示了生产者发送消息、副本管理器进行消息追加操作的过程。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/副本管理器追加消息到 Leader 副本的时序图.png)</p>
<p>图3-30　副本管理器追加消息到 Leader 副本的时序图</p>
<p>需要说明的是，图3-30所示的时序图中 responseCallback() 方法直接返回给客户端，其实 responseCallback() 方法是将消息追加状态实例构造了一个 ResponseSend 对象，由 ResponseSend 对象再实例化一个 Response 对象，并将该对象添加到 RequestChannel 的 responseQueues 队列中，然后由 Processor 线程将追加结果发送给客户端。</p>
<h4 id="6-6-拉取消息"><a href="#6-6-拉取消息" class="headerlink" title="6.6　拉取消息"></a>6.6　拉取消息</h4><p>副本管理器除了负责将消息写入 Leader 副本外，同时还负责处理 KafkaApis 的 FetchRequest 请求，通过 ReplicaManager.fetchMessages() 方法从分区 Leader 副本获取消息，其实是由 KafkaApis 在 handleFetchRequest() 方法中调用 ReplicaManager.fetchMessages() 方法。与 appendMessages() 方法类似，fetchMessages() 方法最后一个参数也是一个回调函数，用于返回消息拉取的结果，同时也是一次 FetchRequest 可以对应多个 TopicAndPartition 发起请求。</p>
<p>在 Kafka 中拉取消息的角色有两个，一个是 Kafka 的普通消费者（相对 Follower 副本而言），另一个就是 Follower 副本，副本管理器是通过 FetchRequest 请求的 replicaId 来区分拉取请求的角色。因为每个副本有 replicaId 属性，即副本的 replicaId 总是非负数，而消费者的 replicaId 为−1。下面对副本管理器处理拉取消息的逻辑进行详细分析。</p>
<p>首先，根据请求的 replicaId 来设置 isFromFollower 值，用于区分是 Follower 副本进行消息同步还是普通消费者拉取消息。如果是消费者拉取消息则应该设置 fetchOnlyCommitted 标识为 true，因为消费者只能消费已提交的消息，也就是说只能消费 HW 位置之前的消息，而对 Follower 副本则需要将该标识字段设置为 false，因为 Follower 副本需要同步 HW 之后的消息。还有一个用于标识是否只从 Leader 副本拉取消息的标识字段 fetchOnlyFromLeader，只有在消费者 debug 模式时该标识才会 false，其他场景该字段恒为 true，对于 debug 模式我们不考虑。</p>
<p>设置好相应标识字段之后，开始调用 ReplicaManager.readFromLocalLog() 方法从 Leader 副本读取消息。在该方法中调用 Log.read() 方法从 Leader 副本中读取消息。从 Leader 副本读取消息之后，如果是 Follower 副本发起的拉取请求，则需要调用 ReplicaManager.updateFollowerLogReadResults() 方法对请求的每个 TopicAndPartition 对应的 Follower 副本进行如下处理。</p>
<p>（1）更新副本的 LEO，因为分区管理副本的操作，因此调用的是该副本对应分区的 updateReplicaLogReadResult() 方法。分区持有一个 assignedReplicaMap 引用，维护了该分区所有副本，从 assignedReplicaMap 中取出当前副本并将所拉取的消息 LogOffsetMetadata 赋值给该副本的 LogOffsetMetadata，完成 LEO 的更新。同时若所拉取消息的偏移量是 Leader 副本的 LEO，则更新该 Follower 副本的 lastCaughtUpTimeMs，即消息同步已追上了 Leader 副本。需要注意的是，这里更新均是对分区 Leader 维护的 Follower 副本相应信息的更新。由于副本从 Leader 副本拉取了消息，此时需要检查是否要扩张 ISR 列表，若该副本已被 Leader 从 ISR 列表中剔除，则将该副本加入 ISR 列表中。将新的 ISR 信息写入 ZooKeeper，同时更新本地维护的 inSyncReplicas 集合信息，并对 Leader 副本的 HW 进行相应检查处理。若对 Leader 副本的 HW 进行了更新，此时需要检查被延迟的操作（DelayedProduce 和 DelayedFetch）是否满足执行条件，让其执行完成。</p>
<p>（2）检查 DelayedProduce 是否满足执行条件，让其执行完成。</p>
<p>然后，检查是否满足立即对 FetchRequest 做出响应的条件，需要立即做出响应的条件如下。</p>
<p>（1）请求的 timeout为0，如果在调用消费者的 poll() 方法时设置 timeout 为 0，则不需要等待拉取消息字节相关的阈值。</p>
<p>（2）FetchRequest 本身没有指定读取消息的分区。</p>
<p>（3）已读取到足够消息，即消息内容已大于 FetchRequest 请求最小字节的限制。</p>
<p>（4）在从 Leader 读取消息时发生了异常。</p>
<p>若满足上述条件之一，则构造相应结果回调 responseCallback() 方法。如果不满足对客户端立即做出响应，那么将读取的结果信息进行处理构造一个 FetchMetadata 对象，然后构造一个 DelayedFetch 对象，交由 delayedFetchPurgatory 进行管理。由 DelayedFetch 在满足执行条件后向客户端做出拉取响应，DelayedFetch 执行所需要满足的条件在3.1.4节有过介绍，此处不再赘述。同样 FetchRequest 的回调函数也是在构造 FetchResponse 之后添加到 RequestChannels 的 responseQueue 队列中，然后由 Processor 处理最终返回给客户端（FetchReqeust 的发起者）。</p>
<p>至此，副本管理器对拉取消息的处理过程分析完毕。处理逻辑基本流程如图3-31所示。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/副本管理器对 FecthRequest 处理的基本流程.png)</p>
<p>图3-31　副本管理器对 FecthRequest 处理的基本流程</p>
<h4 id="6-7-副本同步过程"><a href="#6-7-副本同步过程" class="headerlink" title="6.7　副本同步过程"></a>6.7　副本同步过程</h4><p>上一小节对 Follower 副本从 Leader 副本拉取消息过程进行了介绍，在拉取消息时会更新 Leader 副本中记录的该 Follower 副本的 LEO 信息，当 Follower 副本追上 Leader 副本的 LEO 时，同时会更新该 Follower 副本在 Leader 中的 lastCaughtUpTimeMs。而 Follower 副本对于所同步数据的处理是在 responseCallback 之后进行的。本小节将详细分析副本同步的过程。</p>
<p>在3.6.3节提到过，ReplicaManager 初始化时会创建一个 ReplicaFetcherManager 对象，Follower 副本与 Leader 副本之间的数据同步就是由 ReplicaFecherManager 完成的。ReplicaFetchManager 继承 AbstractFetcherManager 类，该类定义了一个 fetcherThreadMap 用于保存对每个代理的拉取请求的 Fetcher 线程。同时还提供了一个由子类来实现的抽象方法 createFetcherThread()，用于创建拉取线程，以及对 fetcherThreadMap 管理相关的方法，主要包括以下方法。</p>
<ul>
<li>addFetcherForPartitions() 方法：用于为分区添加 Fetcher 线程，其实就是将分区添加到 ReplicaFetcherThread 线程中，一个 ReplicaFetcherThread 可以对应多个分区，也就是说多个分区共用一个 Fetcher 线程，由该 Fetcher 线程负责这些分区的数据拉取操作。fetcherThreadMap 的 Key 是一个 BrokerAndFetcherId 对象，该对象包括两个属性 BrokerEndPoint 和 Fetcher 线程的 id，BrokerEndPoint 封装了连接代理的 host 和 port 信息，Value 为一个 AbstractFetcherThread 对象，在添加分区到 Fetcher 线程时，若 fetcherThreadMap 中还没有与该分区代理连接的 Fetcher 线程，则创建之，否则直接将分区添加到对应的 Fetcher 线程中。</li>
<li>removeFetcherForPartitions() 方法：用于从 fetcherThreadMap 中找到该分区 Fetcher 线程，从 Fetcher 中移除该分区，也就移除了该分区同步数据的线程，在关闭副本时就需要调用该方法，移除相应的 Fetcher 线程。</li>
<li>shutdownIdleFetcherThreads() 方法：当一个 Fetcher 线程不再包含任何分区时，该 Fetcher 线程就会被关闭。</li>
</ul>
<p>ReplicaFetcherManager 继承 AbstractFetcherManager 类，覆盖了 createFetcherThread() 方法，在该方法中创建了一个 ReplicaFetcherThread 线程对象，该线程继承于 AbstractFetcherThread。AbstractFetcherThread 定义的抽象方法 processPartitionData() 由子类来实现，对拉取的消息进行处理，Follower 副本对消息处理就是由 ReplicaFetcherThread 在 processPartitionData() 方法中完成的。而同步请求是在 AbstractFetcherThread 类的 doWork() 方法中发起的，doWork() 方法是线程真正执行体，由线程 run() 方法调用。类之间依赖关系如图3-32所示。</p>
<p>在 AbstractFetcherThread 类中定义了一个 PartitionStates[PartitionFetchState] 类型的 partitionStates 引用，PartitionStates 底层是一个 LinkedHashMap，以 TopicPartition为Key，Value 类型定义为泛型。PartitionFetchState 包括分区的偏移量 offset 以及 Fetcher 线程的状态，因此 partitinStates 维护了分区与分区拉取线程同步的状态。在 AbstractFetcherThread 类的 doWork() 方法中根据 partitionStates 构造 FetchRequest 对象，若 FetchRequst 对象为空即表示当前没有分区要同步，则让线程阻塞<code>${replica.fetch.backoff.ms}</code>毫秒后再重试，当 FetchRequest 不为空时，则调用 AbstractFetcherThread.processFetchRequest() 方法发送 FetchRequest 请求。对于发送请求网络层实现我们不展开介绍。当 FetchRequest 发送后，通过 KafkaApis 处理后调用副本管理器的 fetchMessages() 处理，在前一小节已做详细分析，这里不再赘述。</p>
<p><img src="../../../../../../../../images/2018/10/%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%89%80%E4%BE%9D%E8%B5%96%E7%9A%84%E7%BB%84%E4%BB%B6%E7%9A%84%E7%B1%BB%E5%9B%BE.png" alt="enter image description here"></p>
<p>图3-32　副本同步所依赖的组件的类图</p>
<p>等待 FetchRequest 请求返回拉取结果后，若返回数据不为空，经过一系列数据校验处理后，调用 AbstractFetcherThread 的相应子类实现的 processPartitionData() 方法进行处理。对于副本同步则由 ReplicaFetcherThread.processPartitionData() 方法进行处理，对普通消费者则调用 ConsumerFetcherThread.processPartitionData() 方法进行处理。ReplicaFetcherThread. processPartitionData() 方法对 FetchRequest 返回的数据主要进行以下处理。</p>
<p>（1）将从 Leader 拉取到的数据调用副本的 Log.append() 方法追加到自己日志段中。这里的追加，无需自己生成偏移量 offset 值，直接使用返回数据转换为 ByteBufferMessageSet 对应的偏移量。</p>
<p>（2）取返回数据中附带的 HW 与自己当前的 HW 进行比较，取两者之中较小的更新自己的 HW。</p>
<p>对 ReplicaFetcherThread.processPartitionData() 方法处理逻辑的介绍省略了相关边界校验、异常处理等。副本同步过程介绍至此，我们对同步过程重要环节以如图3-33所示的时序图进行总结。</p>
<p><img src="../../../../../../../../images/2018/10/%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E8%BF%87%E7%A8%8B%E7%9A%84%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt="enter image description here"></p>
<p>图3-33　副本同步过程的时序图</p>
<h4 id="6-8-副本角色转换"><a href="#6-8-副本角色转换" class="headerlink" title="6.8　副本角色转换"></a>6.8　副本角色转换</h4><p>当分区 ISR 发生变化时，控制器会向分区各副本对应的代理发出 LeaderAndIsrRequest 请求，各代理的副本管理器接收到请求后调用 becomeLeaderOrFollower() 方法进行处理。该方法处理逻辑如下。</p>
<p>首先比较 LeaderAndIsrRequest 请求的控制器轮值次数<code>controller_epoch</code>与当前缓存中的<code>local_controller_epoch</code>值是否相等，若不相等，说明当前的请求已是一个过时的控制器发出来的，则不进行任何处理，直接返回<code>Errors.STALE_CONTROLLER_EPOCH.code</code>给控制器；否则对请求中的每个分区状态信息（PartitionStates）迭代进行以下处理。其中分区状态信息即分区在 ZooKeeper的<code>/brokers/topics/${topicName}/partitions/${partitionId}/state</code>节点中记录的分区元数据，包括控制器轮值次数<code>controller_epoch</code>，该分区<code>leader_epoch</code>、该分区 Leader 节点对应的 brokerId，该分区的 ISR 及 AR 信息。</p>
<p>（1）比较分区状态信息的<code>leader_epoch</code>值与缓存中该分区对应的<code>leader_epoch</code>值，为了便于讲解，这里记缓存中的<code>leader_epoch</code>为<code>local_leader_epoch</code>。根据<code>leader_epoch</code>与<code>local_leader_epoch</code>的大小关系分别进行以下处理。</p>
<ul>
<li>若<code>leader_epoch&gt;local_leader_epoch</code>：先检测该分区副本列表中是否包括当前代理，若当前代理不在副本之列，则当前代理直接忽略本次请求，此时将对该分区处理的结果应答码<code>Errors.UNKNOWN_TOPIC_OR_PARTITION.code</code>保存到 responseMap 中，responseMap 是一个被声明为 mutable.HashMap[TopicPartition, Short] 类型的对象；否则将该分区信息保存到 mutable.HashMap [Partition, PartitionState] 类型的 partitionState 对象中。</li>
<li>若<code>leader_epoch&lt;=local_leader_epoch</code>：则当前代理也忽略本次请求，将对分区处理的应答码<code>Errors.STALE_CONTROLLER_EPOCH.code</code>保存到 responseMap 中。</li>
</ul>
<p>（2）过滤 partitionState，依据各分区的 Leader 对应的 brokerId 与本机的 brokerId 是否相等将分区分成 Leader 和 Follower 两个集合，分别记为 partitionsTobeLeader 和 partitionsToBeFollower，即若 Leader 的 brokerId 与本机的 brokerId 相等，则表示当前代理是分区的 Leader 副本所在的代理，否则当前代理是分区 Follower 副本对应的代理。</p>
<p>（3）若 partitionsTobeLeader 集合不为空，则调用 ReplicaManager.makeLeaders() 方法遍历该集合中的每个分区进行处理，使当前代理成为分区的 Leader。若 partitionsToBeFollower 不为空，则调用 ReplicaManager.makeFollowers() 方法使当前代理成为分区的 Follower 副本。</p>
<p>（4）保证更新检查点信息的定时任务启动，通过一个 Boolean 类型的 hwThreadInitialized 变量来控制，若该定时任务已启动，则该变量为 true。该定时任务启动后会每隔<code>${replica.high.watermark. checkpoint.interval.ms}</code>毫秒定时执行，默认是每 5s 执行一次。该定时任务对每个副本可见的偏移量进行持久化。</p>
<p>（5）关闭空闲的 Fetcher 线程。每个 Fetcher 线程负责一定数量的分区数据的同步，当该线程负责同步的分区数为0时，即为空闲的 Fetcher 线程。ReplicaFetcherManager 维护了当前代理分配的所有分区的 Fetcher 线程，当一个分区成为 Leader 时，Fetcher 线程从自己负责同步的分区集合中移除该分区。</p>
<p>（6）回调 onLeadershipChange() 方法，通过 GroupCoordinator 管理分区 Leader 上线/下线操作。</p>
<p>至此，副本管理器对 LeaderAndIsrRequest 请求处理过程介绍完毕。副本管理器对 LeaderAndIsrRequest 请求的处理的基本步骤如图3-34所示。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/副本管理处理 LeaderAndIsrRequest 请求基本流程图.png)</p>
<p>图3-34　副本管理处理 LeaderAndIsrRequest 请求基本流程图</p>
<p>在副本角色转换处理时，提到了将副本转换为 Leader 的 ReplicaManager.makeLeaders() 方法以及将 Leader 转换为 Follower 的 ReplicaManager.makeFollowers() 方法，下面简要分析这两个方法实现副本角色转换的基本逻辑。</p>
<p>ReplicaManager.makeLeaders() 方法负责将指定的副本转为分区 Leader，首先调用 ReplicaFetcherManager.removeFetcherForPartitions() 移除该分区的拉取线程，然后调用 Partition. makerLeader() 方法。</p>
<p>Partition.makeLeader() 方法主要完成以下逻辑。</p>
<p>（1）根据 PartitionState 信息设置 Leader 副本维护的 controllerEpoch，inSyncReplicas，leaderEpoch 字段值以及维护的当前分区所有副本 assignedReplicaMap 集合。</p>
<p>（2）通过将 Leader 的 brokerId 与当前的 brokerId 比较，以判断 Leader 是否发生过变化，若是由 Follower 转换为 Leader 或者分区首次分配，则构造该 Leader 副本的 HW 值，并重设远程副本的 LEO 为 −1。</p>
<p>（3）尝试更新 Leader 副本的 HW，若 Leader 副本的 HW 被更新成功，则检测延迟操作是否满足执行条件，尝试让其执行完成。以 Leader 是否是由 Follower 转换而来作为方法的返回值。</p>
<p>ReplicaManager.makeFollowers() 方法用于将本地副本转换为 Follower 副本。首先检测是否是由 Leader 副本转换为 Follower 副本，若是由 Leader 副本进行转换则先检查新 Leader 是否存活，若新 Leader 副本是存活状态则调用 Partition.makeFollower() 进行副本角色转换，否则创建一个新的副本，这主要是为了保证在 checkpoint 文件中记录有该分区的 HW。副本角色转化成功后若 Partition.makeFollower() 返回 true，表示是由 Leader 转换为 Follower 副本，则将该分区记录到 partitionsToMakeFollower 集合中。然后停止这些副本与旧 Leader 同步的 Fetcher 线程，这样保证当前所有新转换为 Follower 的副本还没有添加对任何分区的 Fetcher 线程。由于 Leader 副本发生了变化，例如，新 Leader 是从副本转换而来，可能导致数据不一致的问题，但 Leader 副本 HW 之前的数据已被各副本同步，因此需要调用 logManager.truncateTo() 方法将日志截取到 HW 的位置，并尝试完成该分区相关的延迟操作。最后调用 ReplicaFetcherManager.addFetcherForPartitions() 方法为新转换的 Follower 副本添加对分区新 Leader 同步的 Fetcher 线程。</p>
<p>Partition.makeFollower() 方法执行逻辑如下。</p>
<p>（1）根据 PartitionState 对象信息获取该分区所有副本 allReplicas 集合及分区新的 Leader，并设置 controllerEpoch 字段值。</p>
<p>（2）轮询 allReplica 集合，调用 Partition.getOrCreateReplica() 方法创建副本。</p>
<p>（3）根据 PartitionState 对像信息更新 assignedReplicaMap 集合，设置 leaderEpoch 和 zkVersion 字段值，由于 Leader 副本维护 ISR，因此设置 Follower 副本的 inSyncReplicas 信息为空集合。</p>
<p>（4）检查 Leader 是否发生了变化，将 Leader 是否发生变化的判断结果作为该方法的返回值。</p>
<h4 id="6-9-关闭副本"><a href="#6-9-关闭副本" class="headerlink" title="6.9　关闭副本"></a>6.9　关闭副本</h4><p>当删除一个主题、分区副本重分配、代理被关闭时由控制器发送 StopReplicaRequest 请求，经由 KafkaApis 收到请求后，在 KafkaApis.handleStopReplicaRequest() 方法中会调用副本管理器关闭副本的 stopReplicas() 方法进行处理。关闭副本操作会对副本状态进行转换操作，例如，删除一个主题时副本状态会经由如图3-35所示的状态变迁过程。</p>
<p><img src="http://images.gitbook.cn/36522550-eb00-11e7-91c8-938c03baf18a" alt="enter image description here"></p>
<p>图3-35　删除主题操作时副本状态转换关系</p>
<p>由图3-35所示可知，在删除主题关闭副本时，其实是同时将该副本删除，然而关闭副本并不一定需要将副本删除，如代理关闭操作，对于这种场景，副本状态可能是由 OnlineReplica 转换为 OfflineReplica 即可。由此对关闭副本操作，通常有两种处理方式：一是将副本下线，二是将副本下线并删除。</p>
<p>下面详细分析副本管理器对关闭副本请求的处理。</p>
<p>首先，副本管理器会检查 stopReplicaRequest 请求所携带的 controllerEpoch 是否小于自己缓存的当前控制器的轮值数 controllerEpoch，若<code>stopReplicaRequest.controllerEpoch&lt;controllerEpoch</code>说明这个请求是由一个已过时的控制器发出的命令，则给予警告信息，拒绝处理，返回<code>STALE_ CONTROLLER_EPOCH</code>信息。否则从 stopReplicaRequest 请求中提取出待关闭副本的所有分区 partitions，并用 stopReplicaRequest 携带的 controllerEpoch 值更新本地缓存的值。</p>
<p>然后，调用 ReplicaFetcherManager.removeFetcherForPartitions() 方法，将待关闭副本的所有分区对应的 Fetcher 从 ReplicaFetcherManager 维护的拉取线程 fetcherThreadMap 中移除，停止该副本数据同步操作。</p>
<p>最后，迭代 partitions 每个分区，调用副本管理器的 stopReplica() 方法进行副本关闭操作，并将副本关闭操作的状态码保存到 responseMap 中。</p>
<p>ReplicaManager.stopReplica() 方法是副本关闭操作的真正执行者。它首先从副本管理器维护的本代理所有分区集合 allPartitions 中集合中移除待关闭副本的分区，若分区存在即表示请求关闭的分区是一个有效分区，并判断请求关闭副本是否要求将副本删除，若需要将副本删除，则调有该分区的 delete() 方法进行日志物理删除操作，删除后再检测被删除的分区对应的主题是否还有其他分区，若不再有该主题的分区，则从 BrokerTopicStats 中移除对该主题追踪的 metrics。如果待删除的分区在 allPartitions 集合不存在，同时关闭副本的请求指定要删除副本，那么就需要构造一个 TopicAndPartition 对象，调用日志管理器从其维护的 logs 集合中找到该主题对应的分区，由日志管理器执行删除该分区的日志文件，即调用 LogManager.deleteLog() 方法处理。</p>
<p>其实，关闭副本的逻辑较简单，主要是关闭副本对应的 Fetcher 线程，让该副本不再执行拉取消息的指令。同时若需要删除副本，则对该副本的日志文件执行物理删除操作。关闭副本操作的流程如图3-36所示。</p>
<p><img src="http://images.gitbook.cn/3b06fad0-eb00-11e7-a17e-99161e35c053" alt="enter image description here"></p>
<p>图3-36　关闭副本操作基本流程图</p>
<h3 id="7-Handler"><a href="#7-Handler" class="headerlink" title="7　Handler"></a>7　Handler</h3><p>在3.4节我们提到的 Handler，其实是 KafkaRequestHandler 的简称。KafkaRequestHandler 是一个线程类，负责从 RequestChannel 中读取请求然后交由 KafkaApis 处理。</p>
<p>在底层实现时，Kafka 实现了一个 KafkaRequestHandlerPool，其作用类似线程池，用于管理 Hander，在 KafkaServer 启动时会实例化一个 KafkaRequestHandlerPool 对象。在 KafkaRequestHanderPool 实例化时会创建<code>${num.io.threads}</code>个 Hander 线程，并以守护线程的方式运行在后台。在 Hander 的 run() 方法中会循环从 RequestChannel 中读取 Request，若 Request 为空，则线程最长会阻塞 300 ms以等待新的 Request，之后再继续去读取 Request，当读取到 Request 后交由 KafkaApis 进行处理。</p>
<p>KafkaApis 提供了一个 hander() 方法，根据 Request.requestId 路由到不同的方法进行处理。当前版本的 Kafka 定义了21种请求，每个请求分别由 KafkaApis 定义的相应方法进行处理。对于较重要的请求，本书在不同章节会穿插进行讲解，这里不再一一进行分析。</p>
<h3 id="8-动态配置管理器"><a href="#8-动态配置管理器" class="headerlink" title="8　动态配置管理器"></a>8　动态配置管理器</h3><p>动态配置管理器（DynamicConfigManager）主要用来对相关配置的变化进行处理，Kafka 将可以通过 ZooKeeper 进行管理的配置划分为4个类型，称为配置类型（ConfigType）或配置级别，每个配置类型称为一个实体（entity），这4个类型分别为 Topic（主题级别）、Client（客户端级别）、User（用户级别）和 Broker（代理级别）。用 entity-type 来指定所属级别，4个级别的 entity-type 依次为 topics，clients，users 和 brokers。</p>
<p>在每个代理启动时会实例化并启动一个动态配置管理器，该管理器会注册一个 ZkNodeChangeNotificationListener 监听器，该监听器实质是注册了一个 IZkChildListener 类型的 NodeChangeListener 用来监听 ZooKeeper 的 /config/change/ 路径下节点的变化。该路径下的节点命名规则为：以<code>“config_change_”</code>字符串作为前辍，之后连接由10位数字（起始为0，不足10位数字左补0）递增组成的字符串，如节点名为<code>“config_change_0000000000”</code>。为了下文讲解方便，将该节点称为通知节点。当该路径下节点发生变化时，若有新的节点创建即表示此时配置发生变化，此时会触发监听器根据 ConfigType 调用相应的 ConfigHandler 进行处理。配置发生变化时在 ZooKeeper 的 /config 路径下有所体现，Kafka 提供了修改配置的工具类：ConfigCommand 类和 TopicCommand 类，客户端可以通过这两个工具类对配置进行修改，在<code>${KAFKA_HOME}/bin</code>目录提供了对配置进行操作的脚本（kafka-topics.sh 和 kafka-configs.sh），通过这两个工具类将对配置的操作写到 ZooKeeper 的 /config 相应节点，具体表现如下。</p>
<p>（1）在<code>/config/&lt;entity-type&gt;</code>路径相应节点下会记录所覆盖的具体配置。相对默认配置而言，对配置的修改即覆盖默认配置，删除对某个配置的修改则该配置值恢复为默认值。</p>
<p>（2）在 /config/changes 目录下创建一个通知节点。</p>
<p>关于这两个节点的详细信息在第5章中会有相应的介绍，在本节我们只关注后台相应处理。当 /config/changes 目录下创建一个新的通知节点时，将会触发监听器，监听器读取 /config/changes 路径下的通知节点，并将节点进行排序，调用配置变化通知处理器 ConfigChangedNotificationHandler 的 processNotifications() 方法进行处理。</p>
<p>通知处理器的 processNotifications() 方法首先从节点名中截取<code>config_changes_</code>之后部分提取出通知编号，每处理一个通知节点就用一个变量 lastExecutedChange 来记录被处理节点的通知编号，这样每次处理时只处理通知编号大于 lastExcecutedChange 值的节点。然后通知处理器根据配置级别 ConfigType 调用相应的配置处理器（ConfigHandler）的 processConfigChanges(entityName: String, value: Properties) 方法进行处理，同时在对4个级别的配置处理时都会调用相应的限流管理器（QuotaManagers）进行相应处理，Kafka 提供了客户端限流管理器（ClientQuotaManager）和副本限流管理器（ReplicationQuotaManager）。客户端限流管理器用来对生产者生产消息或是消费者拉取消息的速率进行处理，副本限流管理器用来对副本同步速率进行处理。4个级别的配置处理器处理逻辑如下。</p>
<p>（1）若是主题级别的配置，则监听器会调用主题级别配置处理器 TopicConfigHandler 进行处理，首先通过日志管理器查询出该主题的所有既有配置，然后重新创建 Properties 对象，将新修改的配置与既有配置进行合并作为该主题的既有配置。同时检测分区副本复制流量（Quota，即每秒操作的字节）控制开关是否发生了变化，若在合并后的配置中查找到对分区副本流量控制开关进行了设置，即开启了分区副本流量控制，则解析出分区与代理对应关系配置，然后调用副本限流管理器将主题分区副本流量控制设置保存到限流管理器维护的 ConcurrentHashMap 集合中，否则会从 ConcurrentHashMap 移除该主题的分区副本流量控制。</p>
<p>主题级别的配置提供了配置项 leader.replication.throttled.replicas 和 follower.replication. throttled.replicas 可以分别对每个分区作为 Leader 和 Follower 时副本流量设置，这里仅是设置对哪个分区与代理的对应关系，而具体流量值通过代理级别的配置 follower.replication.throttled.rate 和 leader.replication.throttled.rate 进行设置，多个分区配置之间以逗号分隔，也支持通配符“*”即对所有的分区开启限流设置。格式为：</p>
<pre><code>follower.replication.throttled.replicas=[partitionId]:[replicaId]或是
follower.replication.throttled.replicas=*</code></pre><p>（2）若是客户端级别或是用户级别配置，则通知处理器分别调用客户端级别配置处理器 ClientIdConfigHandler 和用户级别配置处理器 UserConfigHandler 进行处理。当前版本的 Kafka 在客户端级别和用户级别的配置只对流量控制提供两个有效配置项：<code>producer_byte_rate</code>和<code>consumer_byte_rate</code>分别用来设置生产者向 Kafka 生产消息的速率（每秒字节数）及消费者拉取消息的速率。客户端级别配置处理器或者用户级别配置处理器会调用客户端限流管理器 ClientQuotaManager 对相应的指标配置（MetricConfig）进行更新操作。</p>
<p>客户端级别的配置和用户级别的配置可以组合使用，用来配置某个用户的特定客户端的配置。当组合使用，在 ZooKeeper 的 /conf 路径下节点结构表现形式上客户端级别作为用户级别的子节点，如<code>/config/users/&lt;user&gt;/clients/&lt;client-id&gt;</code>。</p>
<p>（3）若是代理级别的配置，则通知处理器会调用代理级别的配置处理器 BrokerConfigHandler 对配置进行处理。当前版本的 Kafka 在代理级别的配置只提供对节点作为 Leader 或是 Follower 时副本同步数据速率的设置，配置项为 leader.replication.throttled.rate 和 follower.replication.throttled.rate。该配置处理器调用副本限流管理器根据配置项分别对 Leader 和 Follower 同步数据速率进行更新。</p>
<p>以上处理逻辑中各组件的调用关系如图3-37所示。</p>
<p>每次触发监听器对变化节点处理完成后，调用 purgeObsoleteNotifications() 方法将通知节点创建时间与当前时间之差大于通知过期时间（changeExpirationMs）的通知节点删除，通知过期时间固定为 15min。</p>
<p><img src="../../../../../../../../images/2018/10/%E5%8A%A8%E6%80%81%E7%AE%A1%E7%90%86%E5%99%A8%E5%86%85%E9%83%A8%E5%A4%84%E7%90%86%E5%90%84%E7%BB%84%E4%BB%B6%E7%9A%84%E8%B0%83%E7%94%A8%E5%85%B3%E7%B3%BB.png" alt="enter image description here"></p>
<p>图3-37　动态管理器内部处理各组件的调用关系</p>
<h3 id="9-代理健康检测"><a href="#9-代理健康检测" class="headerlink" title="9　代理健康检测"></a>9　代理健康检测</h3><p>Kafka 集群依赖于 ZooKeeper 进行管理，每个代理启动时都向 ZooKeeper 进行一系列元数据的注册，即在 ZooKeeper 相应目录下创建一个临时节点，当代理与 ZooKeeper 连接断开后相应的临时节点也会被删除。Kafka 对代理健康状态检测实现方案较简单，每个代理启动时会在 ZooKeeper 的 /brokers/ids/ 路径下注册自己的 brokerId，并注册一个 SessionExpireListener 监听器，该监听器用来监听代理与 ZooKeeper 连接是否会话 Session 超时，若发生 Session 超时，则与该代理相关的临时节点也会被清除，此时 ZooKeeper 会与当前代理重新创建一条连接，Kafka 健康检测机制就需要重新在 ZooKeeper 上进行注册，创建临时节点并写入相应的元数据信息。</p>
<p>Kafka 健康检测机制实现类是 KafkaHealthcheck，该类实例化时会创建一个 SessionExpireListener 监听器，该监听器实现了 IZkStateListener 接口，在 handleNewSession() 方法中调用 KafkaHealthcheck. register() 方法。KafkaHealthCheck.startup() 方法首先向 ZooKeeper 注册 SessionExpireListener 监听器，然后调用 KafkaHealthcheck.register() 方法，register() 方法将代理节点的连接信息写入到该节点在 ZooKeeper 对应的节点中。</p>
<p>在3.2节我们介绍过 KafkaController 也会在<code>/brokers/ids/${brokerId}</code>节点注册一个监听器，当代理在 ZooKeeper 的 /brokers/ids 路径下创建的临时节点发生变化时会触发控制器进行相应的处理，控制器负责节点上、下线的管理。而健康检测机制的作用就是在检测到临时节点被删除后，如果 ZooKeeper 与当前节点重新连接上，在 ZooKeeper 中重建当前节点在 ZooKeeper 中的临时节点，将节点的连接信息写入该临时节点，以防止当前节点与 ZooKeeper 连接短暂的断开而丢失相应的临时节点及相关的元数据信息。</p>
<h3 id="10-Kafka-内部监控"><a href="#10-Kafka-内部监控" class="headerlink" title="10　Kafka 内部监控"></a>10　Kafka 内部监控</h3><p>Kafka 使用 Yammer Metrics 进行内部状态的监控，用来收集报告 KafkaServer 端和客户端的 metrics 信息，Yammer Metrics 是由 Yammer 提供的一个 Java 库，用于检测 JVM 上相关服务运行的状态。Metrics 能够很好地与 Ganlia 和 Graphite 结合，提供相关的 metrics 图形化接口，可以将 metrics 信息通过 JMX（Java Management Extension）、控制台（Console）、CSV、日志等形式发布出来。Kafka 默认是通过 JMX 来报告 metrics 信息的，将 metrics 指标信息注册成 JMX 的 MBeans，这样就可以通过 JDK 自带的 JConsole 或者 VisualVM 来查看 metrics 信息。当然也通过调用相关 API 来查看相应的 metrics 信息，同时 Kafka 也提供了 CSV 形式的 Reportor (KafkaCSVMetricsReporter)，若想 metrics 以 CSV 形式展示则在 server.properties 文件中加入 CSV 相关配置信息：</p>
<pre><code># metrics 输出时间间隔
kafka.metrics.polling.interval.secs=10
# reporter类
kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter 
# 文件存放目录
kafka.csv.metrics.dir=/opt/data/kafka/metrics
# 是否开启 csvreporter
kafka.csv.metrics.reporter.enabled=true</code></pre><p>这里对 metrics 相关信息不进行介绍，在 Kafka 源码中我们经常看到加入了收集 metrics 信息的代码。例如，在 KafkaServer 启动时，记录代理状态的 metrics 代码：</p>
<pre><code>newGauge(
    &quot;BrokerState&quot;,
    new Gauge[Int] {
      def value = brokerState.currentState
 }</code></pre><p>而相应的工作将由 org.apache.kafka.common.metrics.JmxReporter 及 Kafka 自己实现的 MetricsReporter 来完成。</p>
<p>Kafka metrics 信息已进行了收集，这里将介绍如何通过 JConsole 来查看 Kafka 的 metrics 信息。在 kafka-run-class.sh 脚本中已加入了 JMX 的相关配置信息，接受<code>$JXM_PORT</code>参数，因此在执行依赖与 kafka-run-class.sh 的脚本时，可以在命令中指定<code>JMX_PORT</code>信息。例如，在启动 KafkaServer 时指定<code>JMX_PORT=8888</code>，只要与机器上已分配的端口不冲突的任意端口都可以。</p>
<p>另外需要说明的是，由于网络原因本节是基于我在虚拟机所搭建的 Kafka 环境进行讲解，但这并不影响对 Kafka 内部监控相关内容的介绍。开启 JMX 操作过程如下。</p>
<p>（1）启动代理时指定<code>JMX_POR</code>：</p>
<pre><code>JMX_PORT=8888 ./kafka-server-start.sh ../config/server.properties &amp; </code></pre><p>登录 ZooKeeper 的客户端查看当前代理的元数据信息（如图3-38所示），该代理的<code>jmx_port</code>端口为8888。</p>
<p>![enter image description here](../../../../../../../../images/2018/10/开启 JMX 启动代理时该代理在 ZooKeeper 的元数据信息.png)</p>
<p>图3-38　开启 JMX 启动代理时该代理在 ZooKeeper 的元数据信息</p>
<p>（2）启动 JConsole。在 JDK 安装目录 bin 下执行 JConsole 命令，会弹出 JConsole 连接对话框，在对话框的远程进程中配置要查看代理的 IP 和端口号，在用户名中输入连接代理服务器的用户名及密码（如图3-39所示）。</p>
<p>![enter image description here](../../../../../../../../../../../../images/2018/10/JConsole 新建连接对话框.png)</p>
<p>图3-39　JConsole 新建连接对话框</p>
<p>然后单击“连接”，进入到监控主界面，如图3-40所示。</p>
<p>监控主界面展示有服务器相关的性能，如堆内存、CPU 占用率等。进入 MBean 界面，查看刚才启动的代理相关信息，如图3-41所示。</p>
<p>可以看到 BrokerState 的属性值为 3，即该代理处于 RunningAsBroker 状态。代理状态在第4章中将详细介绍。通过 JConsole 可以查看代理的很多监控信息，如代理的状态、代理拥有的分区、KafkaController 相关信息及选举信息等，在这里不再一一阐述。可以通过 Kafka tools 工具查看 Kafka 所有的 metrics 信息，命令如下：</p>
<pre><code>kafka-run-class.sh  kafka.tools.JmxTool  --jmx-url service:jmx:rmi:///jndi/rmi://morton:
8888/jmxrmi </code></pre><p>![enter image description here](../../../../../../../../../../../../images/2018/10/JConsole 展示的代理服务器信息效果.png)</p>
<p>图3-40　JConsole 展示的代理服务器信息效果</p>
<p>![enter image description here](../../../../../../../../../../../../images/2018/10/JConsole 展示 JMX 采集的代理信息.png)</p>
<p>图3-41　JConsole 展示 JMX 采集的代理信息</p>
<p>这里的 morton 是指待连接的代理所对应的主机名称 hostname，使用该命令需保证代理在启动时已开启 JMX，即指定了<code>JMX_PORT</code>配置。</p>
<p>Kafka 提供的 metrics 有很多，读者可以自行参考[官方网站](<a href="http://kafka.apache.org/documentation#" target="_blank" rel="noopener">http://kafka.apache.org/documentation#</a> monitoring)进行了解。了解 Kafka 内容监控机制，在实际生产中能够帮助我们根据业务需要定制开发 Kafka 集群的监控系统，同时根据相应的 metrics 信息对 Kafka 性能进行调优。</p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://www.asxing.com" rel="external nofollow noreferrer">HoldDie</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://www.asxing.com/2018/10/15/kafka-he-xin-zu-jian-wu/">https://www.asxing.com/2018/10/15/kafka-he-xin-zu-jian-wu/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://www.asxing.com" target="_blank">HoldDie</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Kafka/">
                                    <span class="chip bg-color">Kafka</span>
                                </a>
                            
                                <a href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">
                                    <span class="chip bg-color">消息中间件</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'c4e18e113d94091c8828',
        clientSecret: '891f04d80de6a77fd6eb60d1cbe792e916cde3ff',
        repo: 'asxing.github.io',
        owner: 'Asxing',
        admin: "asxing",
        id: '2018-10-15T19-43-41',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2018/10/15/kafka-he-xin-zu-jian-liu/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="Kafka-核心组件（五）">
                        
                        <span class="card-title">Kafka-核心组件（五）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
胜利只是暂时的，你该警醒，敌人在黑暗中嘲笑自己。 ——真弓·麒麟

3　协调器
Kafka 提供了消费者协调器（ConsumerCoordinator）、组协调器（GroupCoordinator）和任务管理协调器（WorkCoordin
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2018-10-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Kafka/" class="post-category">
                                    Kafka
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Kafka/">
                        <span class="chip bg-color">Kafka</span>
                    </a>
                    
                    <a href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">
                        <span class="chip bg-color">消息中间件</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2018/10/14/kafka-he-xin-zu-jian-si/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Kafka-核心组件（四）">
                        
                        <span class="card-title">Kafka-核心组件（四）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
我脚下的这片土地，埋藏了万千战士的英魂，我因此而颤抖。 ——笑道应有思


Kafka核心功能模块，主要包括延迟操作组件、控制器、协调器、网络通信、日志管理器、副本管理器、动态配置管理器及心跳检测。

1 延迟操作组件
延迟操作组件辅助其
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2018-10-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Kafka/" class="post-category">
                                    Kafka
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Kafka/">
                        <span class="chip bg-color">Kafka</span>
                    </a>
                    
                    <a href="/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">
                        <span class="chip bg-color">消息中间件</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>

    
<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">年份</span>
            <a href="https://www.asxing.com" target="_blank">Asxing</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">479k</span>&nbsp;字
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    window.setTimeout("siteTime()", 1000);
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "10";
                    var startDate = "30";
                    var startHour = "22";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/asxing" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:asxingking@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    

</body>

</html>
