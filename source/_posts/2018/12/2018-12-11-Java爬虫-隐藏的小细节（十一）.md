---
title: Java爬虫-隐藏的小细节（十一）
author: HoldDie
tags: [Java,爬虫]
top: false
date: 2018-12-11 19:43:41
categories: 爬虫
---



**世界上只有两种秘密，骗自己的和以为能骗住别人的。 ——默默**

> 实践小细节

### 一、元素补全

对于页面标签的定位,标签使用

很明显经过html ，自动按html 标准格式化了多了很多标签，实战中也要考虑到这个（html 的类是webmagic那个）

### 2、请求参数:

> Cookie、token、jsessionid注意变化
>
> 还有些不要header不要加 如Content-Length

### 3、浏览器和请求

> **再三提示浏览器不等于请求**

网易云音乐PC页面：

浏览器地址http://music.163.com/#/playlist?id=2203927235

请求地址 http://music.163.com/playlist?id=2203927235

### 4、SSL 问题

主要在HttpClientGenerator方法中

### 5、Post 方法默认是不去重

> 逻辑记得不要重复否则一直会添加post请求

### 6、window 提前关闭

> org.openqa.selenium.NoSuchWindowException: no such window: target window already closed
> from unknown error: web view not found

### 7、定位不准

> [Element is not clickable at point (339, 85). Other element would receive the click](https://stackoverflow.com/questions/30533238/element-is-not-clickable-at-point-339-85-other-element-would-receive-the-cli)

**主要问题,页面还没有加载出来,筛选按钮报错,解决方法: Thread.sleep()**

### 8、Site设置

> 不要乱加refer
>
> 内容addheader不要gzip
>
> 正确是用 .setUseGzip(true)
>
> site放通用header 比如UA cookie
>
> 其他接受内容形式 发送形式 写在request里面

### 9、Xpath

> 不支持.xpath(“//a[contains(text(),’5’)]）
>
> 支持.xpath(“//a[contains(@data,’5’)]）

### 10、Schedule 访问链接去重

实际使用中应考虑去重,当数据量特别大的时候,会出现内存溢出,程序内部使用HashSet实现.