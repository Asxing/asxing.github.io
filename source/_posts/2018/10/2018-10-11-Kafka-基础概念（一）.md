---
title: Kafka-基础概念（一）
author: HoldDie
tags: [Kafka,消息中间件]
top: false
date: 2018-10-11 19:43:41
categories: Kafka
---



> 当你孤傲地站在黄金台上，不要忘了，这一刻所有的刃口都能指向你。 ——沧浪之水

### 基础概念

Kafka 三个关键特性：

- 能够允许发布和订阅流数据
- 存储流数据时提供相应的容错机制
- 当流数据到达时能够被即使处理

#### 1、主题

> Kafka 将一组消息抽象归纳为一个主题（Tipic），也就是说，一个主题就是对一个消息的分类。生产者将消息发送到特定主题，消费者定于主题或主题的某些分区进行消费。

#### 2、消息

> 消息是Kafka通信的基本单位，有一个固定长度的消息头和一个可变长度的消息体构成。在老版本中一条消息称为 Message，在由 Java 重新实现的客户端中，每一条消息称为 Record

#### 3、分区和副本

> Kafka 将一组消息归纳为一个主题，而每个主题又被分成一个或多个分区（Partition）。每个分区由一系列有序、不可变的消息组成，是一个有序队列。

- 每个分区在物理上对应一个文件夹，分区的命名规则为主题名称后接`-` 连接符。
- 分区编号从0开始，编号最大值为分区的总数减一。
- 每个分区又有一至多个副本（Replica），分区的副本在集群的不同代理上，提高可用性。
- 分区的每个副本在逻辑上抽象为日志（Log）对象，即分区的副本与日志对象是一一对应的。
- 每个主题对应的分区数
  - 可以在Kafka启动时所加载的配置文件中配置
  - 也可以在创建主题的时候指定
  - 也可以在创建主题之后修改主题的分区数
- 分区使得Kafka在并发处理上变的容易，理论上，分区的数量越多吞吐量越高。
- 分区也是Kafka保证消息被顺序消费以及对消息负载均衡的基础
- Kafka 只能保证一个分区之内消息的有序性，并不能保证跨分区消息的有序性。
- 每条消息追加到相应的分区中，是顺序写磁盘，因此效率非常高。
- 与传统的消息系统的不同的是，Kafka 并不会立即删除已被消费的消息，当然由于磁盘的限制也不会一直被存储
- Kafka 提供两种删除老数据的策略
  - 基于消息已存储的时间长度
  - 基于分区的大小

#### 4、Leader 副本和 Follower 副本

- 由于副本的存在，多个副本之间的数据一致性如何保证就引入了 Leader 和 Follower 模式。
- 引入 Leader 副本后客户端只需与 Leader 副本进行交互，这样数据一致性及顺序性就有了保证。
- 副本 Follower 与 Leader 的角色并不是一成不变的，当 Leader 失效后，通过相应的选举算法进行选举。

#### 5、偏移量

- 任何发布到分区的消息会被直接追加到日志文件的尾部。
- 每条消息在日志文件中的位置都会对应一个按序递增偏移量。
- 偏移量是一个分区下严格有序的逻辑值，但是并不代表在磁盘上的物理位置。
- 消费之可以通过控制消息偏移量来对消息进行消费，如消费者可以指定消费的起始偏移量。
- 为了保证消息被顺序消费，消费者已消费的消息对应的偏移量也需要保存，换言之，消费者对消息偏移量的操作并不会影响消息本身的偏移量。
- 偏移量的存储
  - 旧版中，存储在Zookeeper中
  - 新版中，存储在内部一个主题中
  - 当然也可以存储在外部系统中

#### 6、日志段

- 一个日志又被划分为多个日志段（LogSegment），日志段是 Kafka 日志对象分片的最小单位。
- 日志段也是一个逻辑概念，一个日志段对应磁盘上一个具体日志文件和两个索引文件。
- 日志文件以`“.log”`为文件名后缀的数据文件，用于保存消息实际数据。
- 两个索引文件分别以`“.index”`和`“.timeindex”`作为文件名后缀，分标表示消息偏移量索引文件和消息时间戳索引文件。

#### 7、代理

- Kafka 集群就是由一个或多个Kafka实例构成，每一个Kafka实例成为一个代理（Broker），通常也称Kafka服务器（KafkaServer）
- 每一个代理都有唯一的标识Id，每增加一个代理就需要在集群中为这个broker分配一个非负整数（不重复），有时我们也称brokerId。
- 由于每个代理分配了不同的brokerId，这样就对应代理进行迁移变得非常方便，对用户透明。

#### 8、生产者

- 生产者负责将消息发送给代理，也就是向Kafka代理发送消息的客户端。

#### 9、消费者和消费组

- 消费者（Consumer）以拉取方式拉取数据，他是消费的客户端。
- Kafka中每一个消费者都属于一个特定的消费组（ConsumerGroup），两者之间的关系是多对一。
- 以GroupId代表消费组名称，通过group.id配置设置，如果不指定消费组，则消费者属于默认消费组 `test-consumer-group`
- 每一个消费者也有一个全局唯一的Id，通过配置项`client.id`指定，如果没有指定，则默认为`${groupId}-${hostName}-${timestamp}-${UUID前8位字符}`格式。
- 同一个主题的一条消息只能被同一个下佛诶组下的某一个消费者消费。
- 不同的消费组的消费者可以同时消费该消息。
- 消费组是Kafka用来实现对一个主题消息进行广播和单播的手段。
- **实现消息广播只需指定各个消费者均属于不同的消费组，消息单播则只需让消费者属于同一个消费组**。

#### 10、ISR

- Kafka 在Zookeeper中动态维护了一个ISR（In-sync Replica），即保存同步的副本列表。
- 该列表中保存了要同步的所有副本节点对应的代理节点ID（brokerId）
- 同时如果一个Follower副本宕机或落后太多，则该Follower副本节点将从ISR列表中移除。

#### 11、Zookeeper

- Kafka利用ZK保存相应元数据信息。
- 元数据信息
  - 代理节点信息、Kafka集群信息、旧版消费者信息、以及消费偏移量信息
  - 主题信息、分区状态信息、分区副本分配方案信息、动态配置信息
- Kafka 在启动和运行过程中，会在ZK中创建相应节点来保存元数据信息。
- Kafka 通过监听机制在这些节点注册相应监听器来监听节点元数据的变化，从而由ZK负责维护Kafka集群。
- 通过ZK可以很方便对Kafka集群进行水平扩展以及数据迁移。

![1ad51e20-eaee-11e7-91c8-938c03baf18a](../../../../../../../../images/2018/10/1ad51e20-eaee-11e7-91c8-938c03baf18a.png)

### 设计概述

支持业务场景

- 具有高吞吐量来支持实时的日志集的大规模事件流
- 很好处理大量积压的数据，以便周期性加载离线数据进行处理
- 能够降低延迟处理传统消息应用场景
- 支持分区、分布式、实时地处理消息，同时具有容忍保障机制。

#### 特征

- 1、消息持久化
  - 采用磁盘线性存储，以文件系统存储数据。
  - 消息系统数据持久化一般采用为每个消费者队列提供一个B树或其他通用的随机访问数据结构来维护消息的元数据，B树操作的时间复杂度为`O(logn)`，但是B树的这些优点并不适合磁盘操作。
  - 同一块磁盘同一时刻只能有一个磁头来读写磁盘，在并发IO能力上就有问题，但是Kafka采用顺序储存，此时时间复杂度就是`O(1)`
  - 由于 Kafka 将消息进行持久化，使得 Kafka 在机器重启后，已存储的消息可继续恢复使用
- 2、高吞吐量
  - Kafka将数据写到磁盘，充分利用磁盘的顺序读写。
  - Kafka在数据写入及数据同步采用了零拷贝（zero-copy）技术，采用 sendFile（）函数调用，sendFile（）函数在两个文件描述符之间直接传递数据，完全在内核中操作，从而避免了内核缓冲区与用户缓存区之间数据的拷贝，操作效率高。
  - 支持数据压缩及批量发送，将每个主题划分为多个分区等操作达到高吞吐量。
- 3、高扩展性
- 4、多客户端支持
- 5、Kafka Streams
- 6、安全机制
- 7、数据备份
- 8、轻量级
- 9、消息压缩
  - 支持Gzip、Snappy、LZ4压缩方式
  - 通常把多个消息放在一起组成MessageSet，然后一起发送。

### 应用场景

- 1、消息系统
- 2、应用监控
- 3、网站用户行为追踪
- 4、流处理
- 5、持久性日志